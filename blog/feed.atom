<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://bkardell.com/</id>
    <title>bkardell.com rss feed</title>
    <updated>2024-09-16T18:31:10.639Z</updated>
    <generator>awesome mix</generator>
    <author>
        <name>Brian Kardell</name>
        <email>bkardell@gmail.com</email>
        <uri>https://bkardell.com</uri>
    </author>
    <link rel="alternate" href="http://bkardell.com/"/>
    <link rel="self" href="https://bkardell.com/blog/feed.atom"/>
    <subtitle>Just the bkardell.com rss feed</subtitle>
    <logo>http://bkardell.com/profile.jpg</logo>
    <rights>All rights reserved 2018, Brian Kardell</rights>
    <entry>
        <title type="html"><![CDATA[Micropayments History]]></title>
        <id>https://bkardell.com/blog/MicropaymentsHistory.html</id>
        <link href="https://bkardell.com/blog/MicropaymentsHistory.html">
        </link>
        <updated>2024-09-16T04:00:00.000Z</updated>
        <summary type="html"><![CDATA[Hey, remember that period when there were like a ton of online 'coins' that people are trying to make happen? And they all kind of wanted to be 'the one', they all involved some kind of crypto thing you didn't totally understand, and they'd all enable micropayments and also solve all of these interesting problems about money. Remember when people were like "let's make an IETF standard!" and others were like "this is a thing we should do at the W3C"?  And then some really big companies got involved?   Do you remember that time... in the mid to late 90s?]]></summary>
        <content type="html"><![CDATA[
	<h1 class="contextual-heading" style="font-size: 2rem;">Micropayments History</h1>

	<p class="segue">Hey, remember that period when there were like a ton of online 'coins' that people are trying to make happen? And they all kind of wanted to be 'the one', they all involved some kind of crypto thing you didn't totally understand, and they'd all enable micropayments and also solve all of these interesting problems about money. Remember when people were like "let's make an IETF standard!" and others were like "this is a thing we should do at the W3C"?  And then some really big companies got involved?   Do you remember that time... in the mid to late 90s?</p>
	
	<p>Because, it totally happened.</p>
	
	<p>Check out this draft of <a href="https://www.w3.org/TR/WD-mptp-951122">Micro Payment Transfer Protocol (MPTP) Version 0.1 from November 1995</a>, and just have a look at the abstract and references section and note how many proposals there already were in 1995. They're pretty hard to find today, unfortunately, lost to the bitrot of time, but here's <a href="https://bkardell.com/media/RivestShamir-mpay.pdf">one, probably slightly updated version (it's dated May 7, 1996) that I was able to dig up as a postscript file and convert to pdf</a>.  It's focused on how you can mint coins cryptographically, and the cost of it and how you can prevent forgery and theft of coins and so on. </p>
	<p>There are minutes from a <a href="https://www.w3.org/ECommerce/JEPI/951218-minutes.html">joint CommerceNet/W3C Electronic Payments Initiative Kickoff meeting which took place in Paris December 18, 1995</a> which was attended by 50+ people from a wide variety of companies from banking and credit cards to telecom and hardwardware systems. In it there is a mention already of "the people looking at micropayments" and pointing out that "with credit card systems there's usually a minimum dollar amount below which a transaction isn't profitable."</p>
	<p>There's this Jan 1996 IETF draft for <a href="https://www.ietf.org/archive/id/draft-eastlake-internet-payment-01.txt">Application Level Internet Payment Syntax</a>, and in Feb 1997 there was another meeting in Paris in which they discussed <a href="https://www.w3.org/ECommerce/Micropayments/Group/micropay-minutes.htm">micropayments</a> and then again in Brussels in Sept 1997.  There's this grab from <a href="https://web.archive.org/web/19970605015010/http://www.w3.org/pub/WWW/Payments/roadmap.html">W3C's Payments Roadmap (the oldest grab here is from 1997, but it's probably older)</a>. Look how much there is!</p>
	<p>There's also <a href="https://web.archive.org/web/19980703170917/http://www12.w3.org/ECommerce/Micropayments/">this link is to a public w3c page</a> which has a lot of links to things which were "already working (more or less)".</p>
	<p>IBM tried this <a href="https://research.ibm.com/publications/minipay-charging-per-click-on-the-web">minipay thing</a>. Carnegie Mellon developed this <a href="https://www.researchgate.net/publication/2417475_NetBill_Security_and_Transaction_Protocol">NETBILL PROJECT in 1997</a>.  </p>
	<p>Jakob Nielsen's Alertbox had a piece in early 1998: <a href="https://web.archive.org/web/20010203213200/http://www.useit.com/alertbox/980125.html">The Case for Micropayments</a> - in which he said "I predict that most sites that are not financed through traditional product sales will move to micropayments in less than two years." Then about <a href="https://web.archive.org/web/20001208142100/http://www.useit.com/alertbox/991226.html">two years later he doubled down saying</a> "I now finally believe that the first wave of micropayment services will hit in 2000."</p>
	<p>He wasn't totally wrong, because then there was Beanz.  </p>
	<p>It was huge.  Here's <a href="https://www.youtube.com/embed/5o9HEjuXsc0?si=vObMl6suQKAtbGMU">a whole 20 minute video someone did on Beanz</a>. But, in short, it earned multiple big rounds of tens of million dollar funding, even $5m just from Larry Ellison.  It had posh offices worldwide and really got a lot of attention.  I guess it started out as mainly a thing like "loyalty points" but that you could spend anywhere. Everyone had loyalty points, but you could only spend them there. So maybe you smoked Marlboro - you earned "Marlboro Miles" and could trade them in for stuff in their catalog. The idea was "why not let me spend my Marlboro miles toward kinda whatever I want".  In the end, that sounds a lot like "almost money".  Today, I guess credit cards have subsumed this a bit, you can get cash back rewards or other things.</p>
	<p>But, it was also totally new and it had a lot of competitors.  Around 2000 we got a big one: Flooz with Whoopi making commercials!  </p>
	<iframe width="560" height="315" src="https://www.youtube.com/embed/AIEpiUJNi5M?si=CsqfZFiaBk3xPoEE" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen=""></iframe>
 
	<p>And in that same year we also got My Points (<a href="https://www.mypoints.com/">still around</a>), Netscentives, CyberGold (<a href="https://www.forbes.com/2000/04/17/mu1.html">quickly aquired by MyPoints for $157m</a>), <a href="https://en.wikipedia.org/wiki/InternetCash.com">internetcash.com</a> and even  <a href="https://en.wikipedia.org/wiki/PayPal"><del>Confinity</del> <del>x.com</del> PayPal</a>.  At the same time all of the new tech was helping regular old transaction costs come down too.</p>
	<p>And then the internet bubble burst.  </p>
	<p>And then <a href="https://web.archive.org/web/20010127094100/http://www.oreillynet.com/lpt/a/515">Clay Shirky wrote "The case against micropayments"</a> which argued pretty strongly that they're just a bad idea.</p>
	<p>It seems the W3C work on this also stopped around that time, in 2001.</p>
	<p>I guess it's never totally stopped. There was, for a minute, <a href="https://www.theguardian.com/technology/2004/may/27/phones.creditcards">Simpay</a> - a consortium formed in 2003 by Orange, T-Mobile, Vodafone, and Telef√≥nica to promote mobile payment solutions across Europe (wow that was 20 years ago?!), and as I say some of those things above still exist, as do other things like <a href="https://fetch.com">fetch.com</a> and, others have been integrated into existing systems more as Clay Shirky predicted.  And, well, of course, there was Bitcoin in 2008 and tons of crypto coins that followed.</p>

	<p>Along the way, in March 2014 the W3C had <a href="https://www.w3.org/2013/10/payments/">a workshop on web payments in Paris</a> which discussed also "new virtual currencies".  Ultimately, the W3C work restarted in 2015 to streamline the online ‚Äúcheck-out‚Äù process and make payments easier and more secure on the Web under the new "<a href="https://www.w3.org/press-releases/2015/webpaymentswg/">Web Payments Working Group</a>."</p>


	<p>Anyway, it was an interesting rabbit hole to dive down, prompted by a number of recent discussions I've had on the health of the web ecosystem and the number of times that something <em>like</em> micropayments seems to come up.  I'll write more about some of those discussions and thoughts in a future post.</p>

	<p class="thanksto">Thanks to my good friend Coralie Mercier for pointing at the rabbit hole and pushing me into it :) And also for a number of pointers and links.</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[1.3 Million Subtests]]></title>
        <id>https://bkardell.com/blog/1_3M-WPTMilestone.html</id>
        <link href="https://bkardell.com/blog/1_3M-WPTMilestone.html">
        </link>
        <updated>2024-09-06T04:00:00.000Z</updated>
        <summary type="html"><![CDATA[Today the Servo project crossed a milestone.]]></summary>
        <content type="html"><![CDATA[
	<h1 class="contextual-heading" style="font-size: 2rem;">1.3 Million Subtests</h1>
	<p class="segue">Today the Servo project crossed a milestone.</p>

	<p>If you're not aware, all of the mainstream browsers that exist today use one of three browser projects/engines (Chromium/Blink, Firefox/Gecko or WebKit).  These in turn both have their roots in projects begun in the late 1990's (Gecko and KHTML).  Further, they have only 1 funding model, and largely 1 funding source.  Over the years, the projects have grown to tens of millions of lines of code and have now had tens of thousands of person years worth of investment.</p>

	<p>All of this is just to underscore that getting a new one is incredibly challenging. Microsoft, a web giant, tried and eventually gave up and embraced Chromium.</p> 

	<p><strong><em>But...</em></strong> If you haven't been paying attention, something very fun and exciting has been developing over the last couple of years.  New life has been breathed into a movement for what we call "novel engines" - that is, engines that don't come from those initial two (khtml/Gecko).</p>

	<p>What's more is that most of the life at least comes from 2 engines which are being developed and funded differently - and they're making rapid progress now.</p>

	<p>As of today, one of those novel engines - Servo (stewarded by Igalia) passes 1.3 <em>million</em> subtests in Web Platform Tests! Specfically: 1,303,530 as of this writing! Congratulations Servo project!</p>

	<figure class="captioned-image">
		<video src="/media/2024/nbc-the-good-place.mp4" loop="" controls="">
	</video></figure>

	<p>For perspective, that's over 73% of the subtests that it's currently running.  Of course, that's a totally arbitrary threshold (kind of a like a birthday), but it's nice to track progress and celebrate milestones and that's a big sounding round number to stop, raise a glass and say "well done!" and "keep up the good work".</p>

	<figure class="captioned-image">
		<img src="/media/2024/Leo_Toasting_meme_banner.jpg">
	</figure>

	<p>Speaking of keeping up the good work: You can join a growing number of others in helping to support the work on Servo directly by donating through <a href="https://github.com/sponsors/servo">GitHub sponsors</a> or our <a href="https://opencollective.com/servo">open collective</a>.  The Servo Technical Steering Committee collectively discusses how to prioritize the spending of available funds in <a href="https://github.com/servo/project/blob/main/governance/tsc/README.md">the public monthly calls</a>. You can also contribute code, reviews and other effort <a href="https://github.com/servo/servo/">via the Servo GitHub repository</a>.  Let's see how quickly we can reach 1.4 million :)</p>

]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[What makes it exciting?]]></title>
        <id>https://bkardell.com/blog/IsThisExciting.html</id>
        <link href="https://bkardell.com/blog/IsThisExciting.html">
        </link>
        <updated>2024-08-29T04:00:00.000Z</updated>
        <summary type="html"><![CDATA[Some thoughts on the things that we get excited about, or don't - and why.]]></summary>
        <content type="html"><![CDATA[
  <h1 class="contextual-heading" style="font-size: 2rem;">What makes it exciting?</h1>
  <p class="segue">Some thoughts on the things that we get excited about, or don't - and why.</p>
  <p>Hey, check this out... </p>
  <figure class="captioned-image"> 
  	<img src="/media/2024/kiosk-mode-or-embedded.png" alt="">
  </figure>
  <p>That's Igalia's website running in Google Chrome in kiosk mode. In kiosk mode there is no surrounding "chrome" and so no rendered <em>controls</em>. It has none of that stuff that we normally associate with "browsers" (tabs, back/forward/refresh buttons, a URL bar, etc)</p>
  <p>In fact, while I say that that's Google Chrome running in kiosk mode, it could just as well be <em>embedded</em> browser, like <a href="https://wpewebkit.org">WPEWebKit</a> which has no built in controls. Is it? </p>
  <p>I'm not telling üòè. </p>
  <p>But, it doesn't really matter: I'm just using it to set up the question of whether you feel like that is a <em>browser</em>? And perhaps whether WPEWebKit excites you as a <em>browser</em>? There's no "right" answer.</p>
  <p>Ok, hold that thought, and look at this...</p>
  <figure class="captioned-image">
  	<img src="/media/2024/webkit-mini.png" alt="">
  </figure>
  <p>This is the webkit.org site running in WebKit mini-browser. It isn't Safari, it is just... er... WebKit. Is it a browser?</p>
  <p>On the one hand, it's right there in the name, right? It's a Mini...<em>browser</em>. And, it does have the most important controls.</p>
  <p>Still, you can't download it as a finished product, you have to build it. And no one thinks you should use this as your daily browser. Does it capture your attention as a browser?</p>
  <p>Probably not?</p>
  <p>Ok, now what about this:</p>
  <figure class="captioned-image">
  	<img src="/media/2024/ladybird.jpeg" alt="">
  </figure>
  <p>That's ladybird. Yes, that's exciting, right?</p>
  <p>I mean, I <em>totally</em> agree...</p>
  <p>But the reason it's exciting has almost nothing to do with it being a <em>browser</em>. The Ladybird browser is hardly more than the mini-browser, in fact. It's purpose it the same and how you get it is the same. What makes it <em>exciting</em> is that it's based on a novel <em>engine</em>.</p>
  <p>That said, excitement isn't currently (or probably for the foreseeable future) of the form "because we can actually <em>use</em> that browser day to day". Unlike in the mini-browsers of the others, there is a lot left to do here and the long tail and tricky bits of the web that are needed are... well, a lot, and tricky. They also have this pesky issue where the more people use your browser, the more bugs and unwritten rules you find you have to manage, all without breaking something else. So, Ladybird's got a long way to get to a place where you can practically use it -- but it is <em>exciting</em>.</p>
  <p>Anyway, I asked some people a while back if they were <em>as</em> excited about Servo and they said "well, but it's not a <em>browser</em>". </p>
  <figure class="captioned-image">
  	<img src="/media/2024/batman-thinking.png" alt="Batman, thinking...">
  	<figcaption>Hmmmmm...</figcaption>
  </figure>
  <p>And, indeed, recently someone from the Servo community created a GitHub repo which <em>will be</em> a browser based on Servo (named <a href="https://github.com/versotile-org/verso">Verso</a> - great name!) and the crowd seemingly <em>did</em> go wild on that (double the points of almost any other Servo related post on the orange website), despite the fact that at the time, it was effectively still a mostly-not-function repo.</p>
  <p>So, anyway... I just wanted to step back and say... </p>
  <section class="sectioning">
    <h2 class="contextual-heading" style="font-size: 2.5rem;">Are you not entertained?</h2>
    <figure class="captioned-image">
    	<img src="/media/2024/servo-mini.png" alt="">
    </figure>
    <p>That's the Servo mini-browser running 3 tabs. And you know how I got it? I went to servo.org, downloaded it, installed it and launched it. I can currently use keyboard commands to launch and close tabs. It's also open source, so anyone could in theory have a better downstream one (maybe Verso?) or help grow a browser in Servo itself (more like Firefox, I guess).</p>
    <p>So... Is Servo a browser?</p>
    <p>I mean... no. But also... yes and it's super exciting.</p>
    <p>You should be excited about it, I think. </p>
    <p>You can help support it with some funding through <a href="https://github.com/sponsors/servo">GitHub</a> or <a href="https://opencollective.com/servo">Open Collective</a> (wealthy donors and business support is welcome too :)).  How to choose and prioritize the work funded by donations is decided through collective discussions on the <a href="https://github.com/servo/project/blob/main/governance/tsc/README.md">public monthly calls of the Servo Technical Steering Committee</a>.</p>
  </section>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[927: Thoughts on a Global Design System]]></title>
        <id>https://bkardell.com/blog/927.html</id>
        <link href="https://bkardell.com/blog/927.html">
        </link>
        <updated>2024-07-18T04:00:00.000Z</updated>
        <summary type="html"><![CDATA[My thoughts on "A Global Design System" as is being discussed in OpenUI.]]></summary>
        <content type="html"><![CDATA[
    <h1 class="contextual-heading" style="font-size: 2rem;">927: Thoughts on a Global Design System</h1>
    <p class="segue">My thoughts on "A Global Design System" as is being discussed in OpenUI.</p>
    
    

    <p>As you may or may not be aware, there's been recent discussion in OpenUI, brought forward by an effort by my fellow Pittsburgher Brad Frost, about the group taking on the effort of creating a <a href="https://bradfrost.com/blog/post/a-global-design-system/">global design system</a>.</p>


    <p>First, let me say that the problem that Brad describes is real, and also not new.  He and I have discussed this in the past as well.  I've spent a lot (the majority maybe) of my career (which began in the 90s) working on projects that were either using, evaluating or making their own common controls.</p>


    <section class="sectioning">
        <h2 class="contextual-heading" style="font-size: 2.5rem;">So much wasted energy</h2>
        <p>While explaining this, Brad frequently notes that inventing and reinventing the same things over and over wastes an enormous amount of human potential. We could be spending that time better.</p>

        <p>I mean... Yes.  I agree.</p>

        <p>But, even more than that, the time spent re-inventing is only part of the story.  The status quo is good for approximately no one.  It also has multiplicative effects far beyond just the actual reinvention..</p>

        <p>There might be 100 toolkits/component libraries which combined have 100k worth of invested hours, and yeah, that's a huge amount of time... Those hours are also <em>wildly</em> skewed. 1 might have 10x or even 100x the thought, care, review and testing than another.</p>

        <p>But while there might be thousands of people spending time re-inventing, there are <em>millions of authors</em> who need components - and so many are spending at least a few hours, or maybe in some cases days searching for suitable components.  I've been involved in corporate evaluations that were weeks of time.  And <strong><em>it's hard</em> to evaluate them</strong> and make good choices that consider accessibility, responsiveness, design, and internationalization.  It is not only time-consuming, we often don't have the skills to do it. That is, after all, one of the reasons we want them: So that we <em>don't</em> each have to know all that stuff.</p>

        <p>But then, how do we expect authors make a good choice?</p>

        <p>Sometimes the ones with the least effort put into them can have a great looking web site, nice documentation, charismatic promotion, or be somehow associated with a big tech company.  Too often we wind up choosing components by proxy and just assuming that something else must mean it's good, and will last a long time.  However, history has not borne that out ‚Äî see the various component toolkits and design systems from even big orgs like Microsoft and Google, for example, that fell by the wayside.
        </p>

        <p>But yeah - multiply that time out... What all of this currently creates is bad all around.  All of the millions of developers looking and ultimately unable to make well-informed choices is probably tens of millions of hours, by comparison.</p>

        <p>In the end, many give up and re-implement again, making the problem even worse.</p>

        <p>Each one might introduce tiny variations and accidentally invent something subtly new and create new challenges for users that we'll spend years sorting out too.</p>

        <p>Ugh. It's bad.  We should want a better future, and <strong>we should act on that</strong>.</p>
    </section>

    <section class="sectioning">
        <h2 class="contextual-heading" style="font-size: 2.5rem;">Imagining a Better Future</h2>
        <p>Here's where I believe we get into trouble though:  We have to be clear on what are we imagining, and whether it is practical/pragmatic to deliver adequate value in a reasonable timeframe.</p>

        <section class="sectioning">
            <h3 class="contextual-heading" style="font-size: 3rem;">Native HTML?</h3>
            <p>We <em>could</em>, for example, choose to imagine that HTML can be given a great and complete set of elements representing a complete UI toolkit.  In addition to correcting all of the issues with the elements we've added so far, this means adding powerful grids connected to data, tabsets, notifications, carousels, charts, and so on. </p>

            <p>Can it? Eventually, maybe, but I hope it is not controversial to suggest that it is extremely unlikely that we could accomplish this with the necessary qualities and in a reasonable timeframe. There's just no information or insight I have that gives me hope that focusing only on that scenario is a good idea.</p>

            <p>This is a good end-goal for many components, but it's not where to start.  It's hard and time consuming and gated on very specific and limited participation of a small number of people. HTML itself moves slow, on purpose.</p>

            <figure class="container"><svg viewBox="0 0 500 30" version="1.1" xmlns="http://www.w3.org/2000/svg" preserveAspectRatio="xMidYMid meet">
              <line x1="0" y1="20" x2="500" y2="20" stroke="black"></line>
             <circle cx="496" cy="20" r="4"></circle>
            </svg>
              <figcaption>I think HTML is at the end of 99 other steps...</figcaption>
            </figure>

            <p><em>The real question, I believe, is about improving how we get there, and deliver iterative partial value along the way</em>.</p>
        </section>

        <section class="sectioning">
            <h3 class="contextual-heading" style="font-size: 3rem;">New Web Components Reference Implementations?</h3>

            <p>It's been suggested that we could work on a single standard with a reference implementation for each component.</p>

            <p>I <em>do</em> believe that ultimately this is a good goal, but I'd like to suggest that it's not where to start either.</p> 

            <p>The challenges to this are less than trying to add it to HTML in some ways, it doesn't require browser vendorts to act in concert, sure.  We can iterate on it, sure.  But the challenges are still huge and trading knowns for unknowns.</p>

            <p>Instead of needing to convince 3 browser vendors to act in concert, we have to convince several UI kit vendors and developers to participate.  We also have to convince everyone to use it and try to avoid XKCD 927 territory...</p>

            <figure>
                <img src="https://imgs.xkcd.com/comics/standards.png">
                <figcaption><a href="https://xkcd.com/927/">XKCD 927</a> 
                        <div>Situation: There are 14 Competing Standards</div>
                        <div>Person 1: 14? Ridiculous! We need to develop one universal standard that covers everyone's use cases!</div>
                        <div>Person 2: Yeah!</div>
                        <div>Situation: There are 15 Competing Standards</div>
                </figcaption>
            </figure>


            <p>This is exacerbated by the fact that it won't come all at once.  It'll still be a non-trivial amount of time before we have a whole library of components which could reasonably be promoted for use.  It still requires people with expertise (probably many of the same people as if it were native) to participate for reviewing accessibility, usability, internationalization, etc.  In practice, there are just very finite resources available to put toward large scale, long term cooperation. Practically speaking, it seems likely we could only focus on a couple of components at a time.</p>

            <p>Let's say we finish and ship the first component: Tabs.  Can we really call it a global design system if it has just one component?  Won't that really limit who can/will adopt it?</p>

            <section class="sectioning">
                <h4 class="contextual-heading" style="font-size: 3.5rem;">Adopt, modify and bless an library</h4>

                <p>It's been suggested that we could take up a library as a kind of a 'donation' project to provide a starting point.  Specifically, maintainers from Shoelace/Web Awesome (also formerly MS components) have volunteered components for this purpose. Not as a "this is the thing" but a "this is a start".  That would give us a nice leap forward.</p>

                <p>Yeah, it would.</p>

                <p>Except... Doesn't it raise a lot of questions we have to answer anyways?</p>

                <p>First, but maybe not as importantly: Why that one? That goes to legitimacy.  We should be able to explain why this is not just the first attractive looking opportunity that presented itself.</p>

                <p>More importantly, it seems to me that the rest of the situation decribed above remains largely unchanged.  We can't seriously promote that until it is deemed "good", and practically speaking it seems that we will approve them individually, not as a library.  So, can't we define how we think it should work before we worry about picking a library?</p>

                <p>The most obvious thing we could have ever done that with was jQuery, and we didn't.</p>


                <figure class="container"><svg viewBox="0 0 500 30" version="1.1" xmlns="http://www.w3.org/2000/svg" preserveAspectRatio="xMidYMid meet">
                  <line x1="0" y1="20" x2="500" y2="20" stroke="black"></line>
                 <circle cx="375" cy="20" r="4"></circle>
                </svg>
                  <figcaption>I think that a library of reference implementations that we can agree to and recommend is still very far along the timeline...</figcaption>
                </figure>


                <p><em>The real question, I believe, is about improving how we get there, and deliver iterative partial value along the way</em>.</p>

                <p>We still don't have a great way to <em>evolve</em> the web - but I keep saying that I think we should.</p>

            </section>
    </section>

    <section class="sectioning">
        <h3 class="contextual-heading" style="font-size: 3rem;">How I think we could get there...</h3>

        <p>This is what I want more than anything:  A plan to get there. Reasonable steps of value along the way, comparatively quickly.</p>

        <p>It is effectively what I thought in 2013-2014 too.  I suggested to the W3C Advisory Committee that we needed to rethink how we approach standards to include this sort of idea, which could work <a href="https://bkardell.com/blog/Dropping-The-F-Bomb-On-Standards.html">more like languages/dictionaries</a>.  I tried to suggest the W3C should create such a process/listing/review process.</p>

        <p>What follows is a vague outline of what I imagine:</p>

        <p>I'd like to create a central place where we lay out some new rules and a process where components, in a basic form that we agree to (it is as a module, should it use shadow dom or not, etc) can be submitted.</p>

        <figure class="container"><svg viewBox="0 0 500 30" version="1.1" xmlns="http://www.w3.org/2000/svg" preserveAspectRatio="xMidYMid meet">
          <line x1="0" y1="20" x2="500" y2="20" stroke="black"></line>
         <circle cx="50" cy="20" r="4"></circle>
        </svg>
          <figcaption>What are the criteria? That's the first few steps...</figcaption>
        </figure>

        <p>We'd define some criteria gating submission, first with IP/license agreements we agree to, possibly some kind of bar for contributors or stars or something, but mainly: A commitment of participation in this new process, especially from experts. Honestly, participation is a bigger part of the limiting factor than anyone really imagines.</p>


        <p>Once submitted it would undergo wide review and get some kind of 'verification stamps' for each kind (a11y, i18n, etc).</p>

        <p>For this reason, I would really love to try to include the authors of government tools here.  They are legally mandated and funded to solve the problem already and seem highly incentivized to participate.  A collective of government efforts also lends immediate credibility and sense of independence to it.</p>

        <p>To me, ideally, we would begin with a call for components/participation.</p>

        <figure class="container"><svg viewBox="0 0 500 30" version="1.1" xmlns="http://www.w3.org/2000/svg" preserveAspectRatio="xMidYMid meet">
          <line x1="0" y1="20" x2="500" y2="20" stroke="black"></line>
         <circle cx="100" cy="20" r="4"></circle>
        </svg>
          <figcaption>A call for particpation/submissions...</figcaption>
        </figure>
    </section>

    <section class="sectioning">
        <h3 class="contextual-heading" style="font-size: 3rem;">You might have noticed...</h3>

        <p>You might have noticed that I didn't answer the question of "how do we pick one?"  That's because I think that's like 99 steps down the road and will come naturally.</p>

        <p>We can get a set of people who can contribute tabs, and a set of people who can review, and we can all discuss several of them at the same time.  We can begin to lay out conformance criteria, and give each one little 'conformance stamps' along the way.  Inevitably we can more easily get implementations to align and develop universal definitions and tests -- new stamps to be had.</p>
        
        <figure class="container"><svg viewBox="0 0 500 30" version="1.1" xmlns="http://www.w3.org/2000/svg" preserveAspectRatio="xMidYMid meet">
          <line x1="0" y1="20" x2="500" y2="20" stroke="black"></line>
         <circle cx="200" cy="20" r="4"></circle>
         <circle cx="240" cy="20" r="4"></circle>
         <circle cx="270" cy="20" r="4"></circle>
        </svg>
          <figcaption>Component get conformance stamps...</figcaption>
        </figure>

        <p>For authors, along the way, there's a nice central catalog somewhere, like webcomponents.org, but better. You'll know those have been submitted, and which ones have which conformance stamps.  Maybe there isn't a 'the one', yet.  But, it's ok?  You have a smaller set, and the information you really need to choose one.  Maybe all 3 of them are ... fine?</p>

        <p>That's not the worst thing, we can sit back and evaluate it for a while while already saving ourselves collectively millions of hours and our users a lot of pain.</p>


        <p>In fact, collecting data and a little variation is <em>good</em>. Probably, they continue to align, or one begins to be the clearer winner.</p>

        <figure class="container"><svg viewBox="0 0 500 30" version="1.1" xmlns="http://www.w3.org/2000/svg" preserveAspectRatio="xMidYMid meet">
          <line x1="0" y1="20" x2="500" y2="20" stroke="black"></line>
         <circle cx="325" cy="20" r="4"></circle>
        </svg>
          <figcaption>We have very well defined, portable criteria for testing and more or less 1 definition...</figcaption>
        </figure>

         <p>And, that's the point: As we go we would slowly, but without stopping major progress at any point.  Even if nothing more happens, each of those steps has had real value.  No one has just <em>wasted</em> time.</p>

        <p>Then, maybe we can get somewhere where we have a single reference implementation of all of those things - or even a standard almost identical to them.</p>

        <figure class="container"><svg viewBox="0 0 500 30" version="1.1" xmlns="http://www.w3.org/2000/svg" preserveAspectRatio="xMidYMid meet">
          <line x1="0" y1="20" x2="500" y2="20" stroke="black"></line>
         <circle cx="400" cy="20" r="4"></circle>
        </svg>
          <figcaption>We have a true global reference implementation... Should we bake it into HTML?</figcaption>
        </figure>

        <p>In any case, that's how I would prefer to approach it. I wouldn't call it a "global design system" to start, because I  wouldn't even start out assuming there would be only one of anything initially... But eventually.</p>

    </section>

</section>]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Improving the WPT Dashboard]]></title>
        <id>https://bkardell.com/blog/WPT-Dashboard.html</id>
        <link href="https://bkardell.com/blog/WPT-Dashboard.html">
        </link>
        <updated>2024-05-21T04:00:00.000Z</updated>
        <summary type="html"><![CDATA[Thoughts on things I'd like to see as part of the WPT dashboard.]]></summary>
        <content type="html"><![CDATA[
    <h1 class="contextual-heading" style="font-size: 2rem;">Improving the WPT Dashboard</h1>
    <p class="segue">Thoughts on things I'd like to see as part of the WPT dashboard.</p>
    
    <p>In my <a href="https://bkardell.com/blog/BSF.html">last post</a> I dug into the data behind <a href="https://wpt.fyi/">wpt.fyi</a>'s Browser Specific Failures chart (below) and the site's general reporting capabilities. </p>
    <figure class="captioned-image">
        <img src="/media/2024/bsf.png" alt="">
    </figure>
    <p>I suggested that linking to data on specifically what failed (at least what is queryable) would probably be really helpful (perhaps some kind of "understanding this chart" link as well).</p>
    <p>While these aren't part of the design today, I think this is mainly because the primary audience of that chart was originally mainly the vendors themselves. It was intended to allow for certain simple kinds of tracking, planning and prioritization. For example "Let's set a goal to not let the failure exceed such and such threshold" or "Let's aim to lower the failures by X this quarter". It wasn't critical to link to the tests because the audience knew how to interrogate the data - the purpose was just to get a quantifiable number you can easily report on.</p>
    <p>But, now we see this chart shared a lot and it's pretty clear that people are curious so we should probably adjust it for the wider audience.</p>
    <p>Additionally though, that's also only a single view of the data, and I'd like to argue that we could some other improvements too.</p>
    <section class="sectioning">
        <h2 class="contextual-heading" style="font-size: 2.5rem;">Prioritization</h2>
        <p>BSF made the observation that if we can identify a test that fails in only 1 browser, then that browser's team can easily prioritize something that has significant impact. That browser is the boat anchor holding things back. Except, it's not quite that cut and dry in reality.</p>
        <p>Real management of software projects is hard. I think that anyone who's worked on software projects can relate to this, at least a bit, if we take some time to consider all of the things that go into choosing how to apply our limited resources. Obviously, not all failures are equal - especially when we're talking about projects which are a quarter of a century old. The reality is that all of that decisioning and prioritization is happening independently across different organizations, with different views on the web, different budgets, different legacy challenges, etc. </p>
        <p>That's where I think there are some things to learn from Interop.</p>
    </section>
    <section class="sectioning">
        <h2 class="contextual-heading" style="font-size: 2.5rem;">What I learned from Interop Is...</h2>
        <p>If you think about it, Interop is about trying to achieve thematically, basically the same thing as BSF: Make more things "green across the board". But it is a <em>very</em> different thing than BSF. </p>
        <p>I've really learned a lot from the process of helping organize Interop every year about why this takes so long to happen naturally. There are so many limits and signals and opinions. One of the things we do as part of the process is to take all of the submissions and independently order them in terms of what we think are their priorities. There are 6 organizations doing that: Apple, Bocoup, Google, Igalia, Microsoft and Mozilla. How many do you think chose the same #1? The answer is 0.</p>
        <p>It really highlights how waiting for all of the stars to align by chance winds up often being a painfully slow process and full of problems. </p>
        <p>However, a <em>huge</em> part of interop is dedicated to dealing with the stuff BSF doesn't really consider - aligning agreement on:
            1. what features are most important
            2. which tests regarding those are valid/important
            3. are all the spec questions really answered?
            4. is this actually (hopefully) achievable in the next year?</p>
        <p>In that, I believe it has been extremely successful in creating way more "green across the board" than anything else. I think this is true beyond even what is <em>officially</em> part of Interop, because we're all able to kind of discuss and see where others are probably going to invest in work because things that were important for them didn't make the cut.</p>
        <p>In a way, each year is sort of like doing what we used to do with "CSS2" and "HTML4"... Creating a more focused discussion that is the goal floor, not the ceiling.</p>
        <details class="note">
            <summary>It's not enough...</summary>
            Sure, I believe this gives us <em>much better results</em> by helping alignment. I think this is obvious given how rapid and smoothly we've found so much high-quality alignment in recent years. However, there's something I want stress in all of this: Choosing what to prioritize is also inherently choosing what to collectively <em>deprioritize</em>. It is inevitable because <strong>at the end of the day there is just too much.</strong>
            <p>The only <em>real</em> solution to this problem is wider investment in the platform and, ultimately, almost certainly, changing how we fund it.</p>
        </details>
        <section class="sectioning">
            <h3 class="contextual-heading" style="font-size: 3rem;">Alignment vs Passing</h3>
            <p>Interop <em>also</em> showed us that a simple, individual pass/fail can be incomplete and misleading. If 3 browsers reach a point of passing 50% of measured tests, the number of tests that pass in <em>all</em> browsers might actually be 0, as illustrated in the table below...</p>
            <figure class="captioned-image">
                <table>
                    <tbody><tr>
                        <th>Chrome
                        </th>
                        <th>Firefox</th>
                        <th>WebKit</th>
                    </tr>
                    <tr>
                        <td>‚úÖ</td>
                        <td></td>
                        <td>‚úÖ</td>
                    </tr>
                    <tr>
                        <td></td>
                        <td>‚úÖ</td>
                        <td>‚úÖ</td>
                    </tr>
                    <tr>
                        <td>‚úÖ</td>
                        <td></td>
                        <td>‚úÖ</td>
                    </tr>
                    <tr>
                        <td></td>
                        <td>‚úÖ</td>
                        <td>‚úÖ</td>
                    </tr>
                    <tr>
                        <td>‚úÖ</td>
                        <td></td>
                        <td>‚úÖ</td>
                    </tr>
                    <tr>
                        <td></td>
                        <td>‚úÖ</td>
                        <td></td>
                    </tr>
                    <tr>
                        <td>‚úÖ</td>
                        <td></td>
                        <td></td>
                    </tr>
                    <tr>
                        <td></td>
                        <td>‚úÖ</td>
                        <td></td>
                    </tr>
                    <tr>
                        <td>‚úÖ</td>
                        <td></td>
                        <td></td>
                    </tr>
                    <tr>
                        <td></td>
                        <td>‚úÖ</td>
                        <td></td>
                    </tr>
                </tbody></table>
                <figcaption>Lots of tests pass, but not even one passes universally!</figcaption>
            </figure>
            <p>In fact, here's a <a href="https://wpt.fyi/results/svg/types/scripted?q=svg&amp;run_id=5095555055484928&amp;run_id=5174632751824896&amp;run_id=5155156954185728&amp;run_id=5128162447196160">real world example of exactly this kind of misleading view in a set of SVG tests</a>. If we look at the numbers across the bottom:</p>
            <ul>
                <li>chrome: 166 / 191 </li>
                <li>edge: 166 / 191 </li>
                <li>firefox: 175 / 191 </li>
                <li>safari: 132 / 191</li>
            </ul>
            <p>It's not <em>terrible</em> if you're only looking at those numbers. But, if you scroll down through that table you'll see that there are ragged failures all over that. In fact, <strong><em>only 52 of 189 are "green across the board"</em></strong>! </p>
            <p>We can only realistically solve by having a more holistic view and working together. BSF is just the slice that is theoretically actionable individually, not everything that matters.</p>
            <section class="sectioning">
                <h4 class="contextual-heading" style="font-size: 3.5rem;">What about a focus on Universally Passing?</h4>
                <p>In the Interop project we track the difference above as its own data point: The Interop number, and we put it as a separate column in the test tables:</p>
                <figure class="captioned-image">
                    <img src="/media/2024/interop-table.png" alt="a table containing a column for each individual browser scores on different features, and a column for the number that pass in all">
                    <figcaption>The interop column reports how many tests pass on <em>all</em> of the tracked browsers</figcaption>
                </figure>
                <p>Similarly, we track it over time:</p>
                <figure class="captioned-image">
                    <img src="/media/2024/interop-graph.png" alt="">
                    <figcaption>A graph showing scores of each browser over time as well as an "interop line"</figcaption>
                </figure>
                <p>Could we learn something from this? Wouldn't something like that be great to have <em>in general</em>? </p>
                <p>For example, in the wpt.fyi tables? Now, it couldn't look just like that because those numbers are all in percentages, and this only really works because the interop process carefully sets a governance process for defining/agreeing to what the tests are. It would be enough to add a column to the table in the same form, something like this:</p>
                <figure class="captioned-image">
                    <img src="/media/2024/universally-passing-table.png" alt="">
                </figure>
                <p>That might help us uncover situations like the SVG one above and present opportunites <em>like</em> interop for us to collectively decide to try to address that.</p>
                <p>Similarly, we could track it over time. Sort of the opposite of BSF. We want to see the simple number of subtests <em>passing</em> in browsers and it should always be going up (even as new tests are added, no existing ones should <em>stop</em> passing - those are just more opportunities to go up). Further, ideally the Universally Passing number shouldn't ever be drawing significantly further away from that over time or we're making less of the platform universal. That is, you could see, over time when we are cooperating better, and when we are not. </p>
                <p>We do better when we are. In my mind, that's an explicit goal, and this would be a view into it.</p>
            </section>
        </section>
    </section>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Brian Specific Failures]]></title>
        <id>https://bkardell.com/blog/BSF.html</id>
        <link href="https://bkardell.com/blog/BSF.html">
        </link>
        <updated>2024-05-09T04:00:00.000Z</updated>
        <summary type="html"><![CDATA[Through my work in Interop, I've been I've been learning stuff about WPT.  Part of this has been driven by a desire to really understand the graph on the main page about browser specific failures (like: which tests?). You might think this is stuff I'd already know, but I didn't.  So, I thought I'd share some of the things I learned along the way, just incase you didn't know either.]]></summary>
        <content type="html"><![CDATA[
    <h1 class="contextual-heading" style="font-size: 2rem;">Brian Specific Failures</h1>
    
    <p class="segue">Through my work in Interop, I've been I've been learning stuff about WPT.  Part of this has been driven by a desire to really understand the graph on the main page about browser specific failures (like: which tests?). You might think this is stuff I'd already know, but I didn't.  So, I thought I'd share some of the things I learned along the way, just incase you didn't know either.</p>

	<p>Did you know that <a href="https://github.com/web-platform-tests/wpt.fyi/blob/main/api/query/README.md">wpt.fyi has lots of ways to query it</a>? It does!</p>

	<p>You can, for example, type <code>nameOfBrowser: fail</code> (or <code>nameOfBrowser: pass</code>) into the search box - and you can even string together several of them to ask interesting questions!</p>
  
    <section class="sectioning">
    	<h2 class="contextual-heading" style="font-size: 2.5rem;">What tests <em>fail in every browser</em>?</h2>

    	<p>It seemed like an interesting question:  Are there tests that fail in <em>every single browser?</em></p>  		
 
    	<p>A query for that might look like: <code>chrome:fail firefox:fail edge:fail safari:fail</code> (using the browsers that are part of Interop, for example).  And, as of this writing, it tells me...</p>  
	    <blockquote> 
	        <p><a href="https://wpt.fyi/results/?label=master&amp;label=experimental&amp;aligned&amp;q=chrome%3Afail%20firefox%3Afail%20edge%3Afail%20safari%3Afail%20">There are 2,724 tests (15,718 subtests) which fail in <em>every single browser</em></a>!</p>
	    </blockquote>

    	<p>Wow.  I didn't expect there to be zero, but that feels like kind of a lot of tests to fail in every browser, doesn't it? How can that even happen? To be totally honest, I don't know! </p>

    	<section class="sectioning">
    		<h3 class="contextual-heading" style="font-size: 3rem;">A chicken and egg problem?</h3>

    		<p>The purpose of WPT is to test conformance to a standard, but this is... tricky.  Tests can be used to discuss specs as they are being written - or highlight things that are yet to be implemented, and WPT doesn't have the same kind of guardrails as specs. Things can get committed there that aren't "real" or yet agreed upon. Frequently the first implementers and experimenters write tests. And, it's not uncommon that then things change - or sometimes the specs just never go anywhere. Maybe those tests sit in a limbo "hoping" to advance?</p>

    		<p><a href="https://web-platform-tests.org/writing-tests/file-names.html">WPT asks</a> that files of early things like this be placed in a <code>/tentative</code> directory or have a <code>.tentative</code> in the names of early things like that which don't have agreement.</p>

    		<p>Luckily thanks to the query API we can see which of the tests above fall into that category by adding <code>is:tentative</code> to our query: <code>chrome:fail firefox:fail edge:fail safari:fail is:tentative</code>). We can see that indeed </p>

    <blockquote>
        <p><a href="https://wpt.fyi/results/?label=master&amp;label=experimental&amp;aligned&amp;q=chrome%3Afail%20firefox%3Afail%20edge%3Afail%20safari%3Afail%20is%3Atentative">348 of the tests (1,911 subtests) that fail in every single browser are marked as tentative</a>. </p>
    </blockquote>
    <p>The query language supports negating parameters with an exclamation, so we can adjust the query (<code>chrome:fail firefox:fail edge:fail safari:fail <em>!is:tentative</em></code>) and see...</p>
    <blockquote>
        <p><a href="https://wpt.fyi/results/?label=master&amp;label=experimental&amp;aligned&amp;q=chrome%3Afail%20firefox%3Afail%20edge%3Afail%20safari%3Afail%20%21is%3Atentative">2,372 tests (13,797 subtests) of the tests that fail in every single browser are not marked as tentative</a>. </p>
    </blockquote>

    <p>So, I guess <code>.tentative</code> doesn't explain most of it (or maybe some of those just didn't follow that guidance). What does? I don't know!</p>

    <p>Poking around, I see there's even 1 ACID test that literally everyone fails. Maybe that's just a bad test at this point? Maybe all of the tests that match this query need reviewed? I don't know!</p>
	</section>

    <p class="note">
        You can also query simply <code>all(status:fail)</code> which will show pretty much the same thing for whatever browsers you happen to be showing.  I like the explicit version for introducing this though as it's very clear from the query itself which "all" I'm referring to about.
    </p>
	</section>

	<section class="sectioning">
		<h2 class="contextual-heading" style="font-size: 2.5rem;">Are there any tests that <em>only pass in one browser?</em></h2>

		<p>I also wondered: Hmm... If there are tests that <em>fail in exactly one browser</em>, and we've just shown there's a bunch that <em>pass in none</em>, how many are there that <em>pass in <em>exactly</em> one</em>? That's pretty interesting to look at too:</p>
	    <ul>
	        <li>5,037 tests (36,446 subtests) which <a href="https://wpt.fyi/results/?label=master&amp;label=experimental&amp;aligned&amp;q=chrome%3Apass%20safari%3Afail%20firefox%3Afail">pass in Chrome, but not in WebKit or Firefox</a>, </li> 
	        <li>1,769 tests (14,273 subtests) which <a href="https://wpt.fyi/results/?label=master&amp;label=experimental&amp;aligned&amp;q=chrome%3Afail%20safari%3Afail%20firefox%3Apass">pass only in Firefox</a> </li>
	        <li>545 tests (3,389 subtests) which pass only in Safari(<a href="https://wpt.fyi/results/?label=master&amp;label=experimental&amp;aligned&amp;q=chrome%3Afail%20safari%3Apass%20firefox%3Afail">https://wpt.fyi/results/?label=master&amp;label=experimental&amp;aligned&amp;q=chrome%3Afail%20safari%3Apass%20firefox%3Afail</a>)</li>
	    </ul>
	    <section class="sectioning">
	    	<h3 class="contextual-heading" style="font-size: 3rem;">Engines and Browsers: Tricky</h3> 
    		
    		<p><em>Often</em> when we're showing results we're using the 3 flagship browsers as a proxy for engine capabilies. We do that a lot - like in the Browsers Specific Failures (BSF) graph at the top of wpt.fyi - but... It's an imperfect proxy.</p>

    		<p>For example, there are also <a href="https://wpt.fyi/results/?label=experimental&amp;label=master&amp;aligned&amp;q=chrome%3Apass%20firefox%3Apass%20edge%3Afail%20safari%3Apass%20">tests that only fail in Edge</a>. As of this writing 1,456 tests (1,727 subtests) of them. </p>

    		<p>Or, there's also <a href="https://wpt.fyi/results/?label=master&amp;label=experimental&amp;product=chrome&amp;product=edge&amp;product=firefox&amp;product=safari&amp;product=webkitgtk&amp;aligned&amp;q=chrome%3Apass%20firefox%3Apass%20edge%3Apass%20safari%3Apass%20gtk%3Afail">tests that fail uniquely in WebKit GTK</a> - 1,459 tests (1,740 subtests) of those.</p>

    		<p>Here's where there's a bit of a catch-22 though.  BSF is really useful for the browser teams, so links like the above are actually very handy if you're on the Edge or GTK teams.  But we can't add those to the BSF chart because it kind of really changes the meaning of the whole thing.  What that kind of wants to be is "Engine Specific Failures", but that's not actually directly measurable.</p>
    	</section>
    </section>
    <section class="sectioning">
    	<h2 class="contextual-heading" style="font-size: 2.5rem;">Brian Specific Failures...</h2>
    	
    	<p>Below is an interesting table which links to query results that show actual tests that report as failing in only one of the three flagship browsers.</p>
    <table>
        <thead>
            <tr>
                <th align="left">Browser</th>
                <th align="left">Non-tentative Subtests which uniquely fail among these browsers</th>
            </tr>
        </thead>
        <tbody>
            <tr>
                <td align="left">Chrome</td>
                <td align="left"><a href="https://wpt.fyi/results/?label=master&amp;label=experimental&amp;product=chrome&amp;product=firefox&amp;product=safari&amp;aligned&amp;q=chrome%3Afail%20firefox%3Apass%20safari%3Apass">1,345 tests (12,091 subtests)</a></td>
            </tr>
            <tr>
                <td align="left">Firefox</td>
                <td align="left"><a href="https://wpt.fyi/results/?label=master&amp;label=experimental&amp;product=chrome&amp;product=firefox&amp;product=safari&amp;aligned&amp;q=chrome%3Apass%20firefox%3Afail%20safari%3Apass%20%21is%3Atentative">2,290 tests (16,791 subtests)</a></td>
            </tr>
            <tr>
                <td align="left">Safari</td>
                <td align="left"><a href="https://wpt.fyi/results/?label=master&amp;label=experimental&amp;product=chrome&amp;product=firefox&amp;product=safari&amp;aligned&amp;q=chrome%3Apass%20firefox%3Apass%20safari%3Afail">4,263 tests (14,867 subtests)</a></td>
            </tr>
        </tbody>
    </table>

    <p>If that sounds like the data for the Browser Specific Failures (BSF) graph on the front page of wpt.fyi, yes.  And no.  I call this the "Brian Specific Failures" (BSF) table.</p>

    <figure class="captioned-image">
    	<img src="/media/2024/isthisthedata.jpg">
    </figure>

    <p>I think that this is about as close as we're probably going to get in the short term to a linkable set of tests that fail, if you'd like to explore them.  The BSF graph is also, I believe, more disciminating than just "pass" and "fail" that we're showing here.  Like, what do you do if a test times out? Are there intermediate or currently unknown statuses?</p>

    <p>It was also kind of interesting, for me at least, while looking at the data, to realize just how different the situation looks depending on whether you are looking at tests, or subtests. Firefox fails the most subtests, but Safari fails the most tests.  BSF "scores" subtests as decimal values of a whole test.</p>

    <p>It's pretty complicated to pull any of this off actually. Things go wrong with tests and runs, and so on. I also realized that all of these scores are inherently a little imperfect.</p>

	<p>For example, if you at the top of the page, it says (as I am writing this) there are 55,176 tests (1,866,346 subtests)</p>

    <figure class="captioned-image">
    	<img src="/media/2024/wpt-1.png" alt="&quot;Showing 55176 tests (1866346 subtests)&quot;">
    </figure>
    
    <p>But if you look to the bottom of the screen, the table has a summary with the passing/total subtests for each browser. As I am writing this it says: </p>
    
    <figure class="captioned-image"><img src="/media/2024/wpt-2.png" alt="chrome: 1836812 / 1890027, edge: 1834777 / 1887771, firefox: 1786949 / 1868316, safari: 1787112 / 1879926">
    </figure>

    <p>You might note that <em>none of those lists the same number of subtests</em>!</p>

	</section>

	<p>Anyway, it was an interesting rabbit hole to dive into!  I have further thoughts on the WPT.fyi dashboard page which I'll share in another post, but I'd love to hear of any interesting queries that you come up with or questions you have. I probably don't know the answers, but I'll try to help find them!</p>

]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Known Knowns]]></title>
        <id>https://bkardell.com/blog/known-knowns.html</id>
        <link href="https://bkardell.com/blog/known-knowns.html">
        </link>
        <updated>2024-05-04T04:00:00.000Z</updated>
        <summary type="html"><![CDATA[Fun with the DOM, the parser, illogical trees and "unknowns"...]]></summary>
        <content type="html"><![CDATA[
    <h1 class="contextual-heading" style="font-size: 2rem;">Known Knowns</h1>
    <p class="segue">Fun with the DOM, the parser, illogical trees and "unknowns"...</p>
    <script src="../prism.js"></script>
    <link rel="stylesheet" href="../prism.css">
    
    
    <p>HTML has this very tricky parser that does 'corrections' and things on the fly. So if you create a page like:</p>
    <pre><code class="language-html">&lt;table&gt;
   Hello
   &lt;td&gt;
      Look below...
   &lt;/td&gt;
&lt;/table&gt;
</code></pre>
    <p>And load it in your browser, what you'll actually get parsed as a tree will be </p>
    <ul class="domTree">
        <li class="t1"><code class="language-html">HTML</code>
            <ul>
                <li class="t1"><code class="language-html">HEAD</code></li>
                <li class="t1"><code class="language-html">BODY</code>
                    <ul>
                        <li class="t3"><code class="language-html">#text</code>: <span>
                                Hello
                            </span></li>
                        <li class="t1"><code class="language-html">TABLE</code>
                            <ul>
                                <li class="t1"><code class="language-html">TBODY</code>
                                    <ul>
                                        <li class="t1"><code class="language-html">TR</code>
                                            <ul>
                                                <li class="t1"><code class="language-html">TD</code>
                                                    <ul>
                                                        <li class="t3"><code class="language-html">#text</code>: <span>
                                                                Look below...
                                                            </span></li>
                                                    </ul>
                                                </li>
                                                <li class="t3"><code class="language-html">#text</code>: <span>
                                                    </span></li>
                                            </ul>
                                        </li>
                                    </ul>
                                </li>
                            </ul>
                        </li>
                    </ul>
                </li>
            </ul>
        </li>
    </ul>
    <p>Things can literally be moved around, implied elements added and so on. </p>
    <section class="sectioning">
        <h2 class="contextual-heading" style="font-size: 2.5rem;">Illogical trees</h2>
        <p>But it's not impossible to create trees that are impossible to create with the parser itself, if you do it dynamically. With the DOM API, you can create whatever wild constructs you want: Paragraphs inside of paragraphs? Sure, why not.</p>
        <p>Or, <a href="https://software.hixie.ch/utilities/js/live-dom-viewer/?%3C!DOCTYPE%20html%3E%0A%3Ctable%20id%3D%22one%22%3E%3C%2Ftable%3E%0A%0A%3Cscript%3E%0A%20%20%20one.appendChild(%0A%20%20%20%20%20document.createTextNode(%22test%22)%0A%20%20%20)%0A%3C%2Fscript%3E">text that is a direct child of a table</a>. Note this still renders the text in every browser engine.</p>
        <p>You can even add children to 'void' elements that way too. Here's an interesting one: <a href="https://software.hixie.ch/utilities/js/live-dom-viewer/?%3C!DOCTYPE%20html%3E%0A%3Chr%20id%3D%22one%22%3E%0A%0A%3Cscript%3E%0A%20%20%20one.appendChild(%0A%20%20%20%20%20document.createTextNode(%22test%22)%0A%20%20%20)%0A%3C%2Fscript%3E">An <code>&lt;hr&gt;</code> with a text node child</a>. Again, It renders the text in every browser engine (the color varies).</p>
        <p>You can also put unknown elements into your markup and the text content is shown... By default, it is basically a <code>&lt;span&gt;</code>.</p>
        <p>In <em>most cases</em>, HTML wants to show something... or at least leave CSS in control. For example, you can dynamically add children to a <code>&lt;script&gt;</code>. While that won't be shown by default, it's simply because the UA style sheet has script set to <code>display: none;</code>. If we change that, <a href="https://software.hixie.ch/utilities/js/live-dom-viewer/?%3C!DOCTYPE%20html%3E%0A%3Cstyle%3E%0A%20%20%20script%20%7B%20display%3A%20block%3B%20%7D%0A%3C%2Fstyle%3E%0A%3Cbody%3E%0A%20%20%3Cdiv%20id%3Dtwo%20style%3D%22background%3A%20pink%22%3EInteresting!%3C%2Fdiv%3E%0A%3Cscript%20id%3D%22one%22%3E%0A%20%20%20one.appendChild(two)%0A%3C%2Fscript%3E">we can totally see it</a>.</p>
        <p>But this isn't universal: In some cases there are other renderers that are in control - mainly when it comes to form controls. But also, for example, if you switch the <code>&lt;hr&gt;</code> in the example above to a <code>&lt;br&gt;</code> it won't render the text. It doesn't generate a box that you can do anything with with CSS as far as I can tell, except make it <code>display: none</code> (useful if they‚Äôre in <code>white-space: pre</code> blocks to keep them from forcing open extra lines).
    </p></section>
    <section class="sectioning">
        <h2 class="contextual-heading" style="font-size: 2.5rem;">SVG</h2>
        <p>The HTML parser has fix ups for embedding SVG too, there are kind of integration points. But, in SVG you can have an unknown element too... For example:</p>
        <pre><code class="language-html">&lt;svg&gt;
    &lt;unknown&gt;Test&lt;unknown&gt;
    &lt;rect width="150" height="150" x="10" y="10" style="fill:blue;stroke:pink;stroke-width:5;opacity:0.5" /&gt;
&lt;/svg&gt;
</code></pre>
        <p>The unknown element won't render the text, nor additional SVG children inside it. For example:</p>
        <pre><code class="language-html">&lt;svg id=one width="300" height="170"&gt;
  &lt;unknown&gt;&lt;ellipse cx="120" cy="80" rx="100" ry="50" style="fill:yellow;stroke:green;stroke-width:3" /&gt;&lt;/unknown&gt;
&nbsp; &lt;rect width="150" height="150" x="10" y="10" style="fill:blue;stroke:pink;stroke-width:5;opacity:0.5" /&gt;
&lt;/svg&gt;
</code></pre>
    </section>
    <section class="sectioning">
        <h2 class="contextual-heading" style="font-size: 2.5rem;">MathML</h2>
        <p>As you might expect, there are parser integrations for MathML too, and you can have an unknown elements in MathML too. In MathML, all elements (including unknown ones) generate a "math content box", but only <em>token</em> elements (like <code>&lt;mi&gt;</code>, <code>&lt;mo&gt;</code>, <code>&lt;mn&gt;</code>) render text. For example, the <code>&lt;math&gt;</code> element itself - if you try to put text in it, the text won't render, but it will still generate a box and other content.</p>
        <pre><code class="language-html">&lt;math&gt;
   Not a token. Doesn't render.
   &lt;mi&gt;X&lt;/mi&gt;
&lt;/math&gt;
</code></pre>
        <p>MathML has other elements too like <code>&lt;mrow&gt;</code> and <code>&lt;mspace&gt;</code> and <code>&lt;mphantom&gt;</code> which are just containers. Same story there, if you try to put text in them, the text won't render... </p>
        <pre><code class="language-html">&lt;math&gt;
   &lt;mrow&gt;Not a token. Doesn't render.&lt;/mrow&gt;
   &lt;mi&gt;X&lt;/mi&gt;
&lt;/math&gt;
</code></pre>
        <p><em>But</em> if you put the text inside a token element (like <code>&lt;mi&gt;</code>) inside that same <code>&lt;mrow&gt;</code>, then the text will render..</p>
        <pre><code class="language-html">&lt;math&gt;
   &lt;mrow&gt;&lt;mi&gt;ok&lt;/mi&gt;&lt;/mrow&gt;
   &lt;mi&gt;X&lt;/mi&gt;
&lt;/math&gt;
</code></pre>
        <p>In MathML, unknown elements are basically treated just like <code>&lt;mrow&gt;</code>. In the above examples, you could replace <code>&lt;mrow&gt;</code> with <code>&lt;unknown&gt;</code> and it'd be the same.</p>
    </section>
    <section class="sectioning">
        <h2 class="contextual-heading" style="font-size: 2.5rem;">Unknown Unknowns</h2>
        <p>Ok, here's something you don't think about every day: Given this markup:</p>
        <pre><code class="language-html">&lt;unknown id=one&gt;One&lt;/unknown&gt;
&lt;math&gt;
  &lt;unknown id=two&gt;Two&lt;/unknown&gt;
&lt;/math&gt;
&lt;svg&gt;
  &lt;unknown id=three&gt;Three&lt;/unknown&gt;
&lt;/svg&gt;
</code></pre>
        <p><code>One</code>, <code>Two</code> and <code>Three</code> are <strong><em>three different kinds of unknowns</em></strong>!</p>
        <pre><code class="language-javascript">console.log(one.namespaceURI, one.constructor.name)
// logs 'http://www.w3.org/1999/xhtml HTMLUnknownElement'

console.log(two.namespaceURI, two.constructor.name)
// logs 'http://www.w3.org/1998/Math/MathML MathMLElement'

console.log(three.namespaceURI, three.constructor.name)
// logs 'http://www.w3.org/2000/svg SVGElement`
</code></pre>
        <p>In CSS, these can also (theoretically) be styled via namespaces. The following will only style the first of those:</p>
        <pre><code class="language-css">@namespace html url(http://www.w3.org/1999/xhtml);
html|unknown { color: blue; }
</code></pre>
    </section>
    <section class="sectioning">
        <h2 class="contextual-heading" style="font-size: 2.5rem;">Under-defined Unknowns</h2>
        <p>Remember how in the beginning we created nonsensical constructs dynamically? Well, we can do that here too. We can move an unknown <code>MathMLElement</code> right into HTML, or an unknown <code>HTMLElement</code> right into MathML, and so on - and it's not currently well-defined, universal, or consistent what actually happens here.</p>
        <p><a href="https://codepen.io/briankardell/pen/ExJzOXK">Here's an interesting example</a> moves an unknown <code>MathMLElement</code> and a <code>SVGElement</code> into HTML, and an <code>HTMLElement</code> into MathML and so on</p>
        <p class="codepen" data-height="300" data-default-tab="html,result" data-slug-hash="ExJzOXK" data-user="briankardell" style="height: 300px; box-sizing: border-box; display: flex; align-items: center; justify-content: center; border: 2px solid; margin: 1em 0; padding: 1em;">
            <span>See the Pen <a href="https://codepen.io/briankardell/pen/ExJzOXK">
                    Untitled</a> by –≤–∫Œ±—è‚àÇŒµ‚Ñì‚Ñì (<a href="https://codepen.io/briankardell">@briankardell</a>)
                on <a href="https://codepen.io">CodePen</a>.</span>
        </p>
        <script async="" src="https://cpwebassets.codepen.io/assets/embed/ei.js"></script>
        <p> Here's how that renders in the various today:</p>
        <figure>
            <img src="https://notes.igalia.com/uploads/331613fd-0d93-4126-a746-646b3aa114f9.png">
            <figcaption>Left to right: Chrome, Firefox, Safari all render differently</figcaption>
        </figure>
        <p>So, I guess we should probably fix that. I'll have to start creating some issues and tentative tests (feel free to beat me to it üòâ)</p>
    </section>
    <section class="sectioning">
        <h2 class="contextual-heading" style="font-size: 2.5rem;">Semi-related Rabbit Holes</h2>
        <p>Not specifically these issues, but related namespace stuff has caused a lot of problems that we're remedying as shown by a recent flurry of activity started by my colleague Luke Warlow to fix MathML-Core support in various libraries/frameworks:</p>
        <ul>
            <li><a href="https://github.com/sveltejs/svelte/pull/11387">Svelte 5</a></li>
            <li><a href="https://github.com/preactjs/preact/pull/4364">Preact</a> </li>
            <li><a href="https://github.com/angular/angular/issues/55608">Angular</a></li>
            <li><a href="https://github.com/lit/lit/pull/4637">Lit</a></li>
        </ul>
        <p>Who's next? :)</p>
    </section>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Mirror Effects]]></title>
        <id>https://bkardell.com/blog/mirror-effects.html</id>
        <link href="https://bkardell.com/blog/mirror-effects.html">
        </link>
        <updated>2024-04-22T04:00:00.000Z</updated>
        <summary type="html"><![CDATA[Today I had this thought about "AI" that felt more like a short blog post than a social media thread, so I thought I'd share it.]]></summary>
        <content type="html"><![CDATA[
	<h1 class="contextual-heading" style="font-size: 2rem;">Mirror Effects</h1>
	<p class="segue">Today I had this thought about "AI" that felt more like a short blog post than a social media thread, so I thought I'd share it.</p>

	<p>I love learning and thinking about weird indirect connections like how thing X made things Y and Z suddenly possible, and given some time these had secondary or tertiary impacts that were really unexpected.</p>

	<p>There are so many possible examples:  We didn't really expect the web and social media to give rise to the Arab Spring.  Nor to such disinformation.  Nor the 2016 American election (or several others similarly around the world).  Maybe Carrier didn't expect that the invention of air conditioning would help reshape the American political map, <a href="https://www.pbs.org/newshour/show/did-air-conditioning-play-a-role-in-reagans-election-searching-for-ripple-effects-of-history-making-tech">but it did</a>.</p>

	<p>One of the things that came to my mind today  was a thing I read about mirrors.  Ian Mortimer explains how improvements to and the spread of mirrors radically changed lots of things. Here's a quote from the piece:

	</p><blockquote>
	The very act of a person seeing himself in a mirror or being represented in a portrait as the center of attention encouraged him to think of himself in a different way. He began to see himself as unique. Previously the parameters of individual identity had been limited to an individual‚Äôs interaction with the people around him and the religious insights he had over the course of his life. Thus individuality as we understand it today did not exist;  people only understood their identity in relation to groups‚Äîtheir household, their manor, their town or parish‚Äîand in relation to God... 
	<cite><a href="https://www.laphamsquarterly.org/roundtable/mirror-effect">The Mirror Effect</a></cite>
	</blockquote>

	<p>It's pretty interesting to look back and observe all of the changes that this began to stir - from the way people literally lived (more privacy), to changes in the types of writing and art, and how we thought about fitting in to the larger world (and thus the societies we built).</p>

	<p>So, today I had this random thought that I wonder what sorts of effects like these will come from all of the "AI" focus. That is, not the common/direct sorts of things we're talking about but the ones that maybe have very little to do with any actual technology even.  Which things will some future us look back on in 20 or 100 years and say "huh, interesting".</p>

	<p>In particular, the thing that brought this to mind is that I am suddenly seeing lots of more people suddenly having conversations like "What is consciousness though, really?" and "What is intelligence, really?". I don't mean from technologists, I just mean it seems to be causing lots more people to suddenly think about that kind of thing.</p>

	<p>So it made me think: I wonder if we will see increased signups for philosophy courses? Or,  sales of more books along these lines?  Could that ultimately lead to another, similar sort of changing in how we collectively see ourselves?  I wonder what effects this has in the long term on literature, film, or even science and government.</p>

	<p>This isn't a "take" - it's not trying to be optimistic or pessimistic.  It's more of a "huh... I hadn't thought much about that before, but it's kind of interesting to think about."  Don't you think?  Outside of the normal sorts of things we're obviously thinking about - what are some you could imagine?</p>

	<p>As a kind of final interesting note: Stephen Johnson is a great storyteller, and his work is full of connections like these.  If you want to read more, <a href="https://en.wikipedia.org/wiki/Steven_Johnson_(author)#Books">check out his books</a>.  Part of the reason that I mention him is that interestingly, it seems that he <a href="https://stevenberlinjohnson.com/writing-at-the-speed-of-thought-21dfb7f689e4">has recently gone to work with Google on a LM project about writing himself</a>. I bet he's got some notes and ideas on this already too.</p> 

]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[The Blessing of the Strings]]></title>
        <id>https://bkardell.com/blog/blessing-strings.html</id>
        <link href="https://bkardell.com/blog/blessing-strings.html">
        </link>
        <updated>2024-04-03T04:00:00.000Z</updated>
        <summary type="html"><![CDATA[Trusted Types have been a proposal by Google for quite some time at this point, but it's currently getting a lot of attention and work in all browsers (Igalia is working on implementations in WebKit and Gecko, sponsored by Salesforce and Google, respectively). I've been looking at it a lot and thought it's probably something worth writing about.]]></summary>
        <content type="html"><![CDATA[
    <h1 class="contextual-heading" style="font-size: 2rem;">The Blessing of the Strings</h1>
    <p class="segue">Trusted Types have been a proposal by Google for quite some time at this point, but it's currently getting a lot of attention and work in all browsers (Igalia is working on implementations in WebKit and Gecko, sponsored by Salesforce and Google, respectively). I've been looking at it a lot and thought it's probably something worth writing about.</p>
    <script src="../prism.js"></script>
    <link rel="stylesheet" href="../prism.css">
    
    <p>The Trusted Types proposal is about preventing Cross-site scripting (XSS), and rides atop Content Security Policy (CSP) and allows website maintainers to say "require trusted-types". Once required, lots of the Web Platform's dangerous API surfaces ("sinks") which currently require a string will now require... well, a <em>different</em> type.</p>
    <p><code>myElement.innerHTML</code> (and a whole lot of other APIs) for example, would now require a <code>TrustedHTML</code> object instead of just a string.</p>
    <p>You can think of <code>TrustedHTML</code> as an interface indicating that a string has been somehow specially "blessed" as safe... Sanitized.</p>
    <figure class="captioned-image">
    	<img src="/media/2024/holy.gif" style="width:100%;max-width:800px;" alt="the Holy Hand grenade scene from Monty Python's Holy Grail">
    	<figcaption>And Saint Attila raised the string up on high, saying, 'O Lord, bless this thy string, that with it we may trust that it is free of XSS...' <a href="https://www.youtube.com/watch?v=xOrgLj9lOwk">[ref]</a>.</figcaption>
    </figure>
    <section class="sectioning">
        <h2 class="contextual-heading" id="blessing-strings" style="font-size: 2.5rem;">Granting Blessings</h2>
        <p>The interesting thing about this is how one goes about blessing strings, and how this changes the dynamics of development and safety to protect from XSS.</p>
        <p>To start with, there is a new global <code>trustedTypes</code> object (available in both window and workers) with a method called <code>.createPolicy</code> which can be used to create "policies" for blessing various kinds of input (<code>createHTML</code>, <code>createScript</code>, and <code>createScriptURL</code>). Trusted Types comes with the concept of a <em>default</em> policy, and the ability for you to register a specially named "default"...</p>
        <pre><code class="language-javascript">//returns a policy, but you 
// don't really need to do anything 
// with the default one
trustedTypes.createPolicy(
    "default", 
    {
      createHTML: s =&gt; { 
          return DOMPurify.sanitize(s) 
      } 
    }
);</code></pre>
        <p>And now, the practical upshot is that <em>all attempts to set HTML will be sanitized</em>... So if there's some code that tries to do:</p>
        <pre><code class="language-javascript">// if str contains
// `&amp;lt;img src="no" onerror="&lt;em&gt;dangerous code&lt;/em&gt;" &amp;gt;`;
target.innerHTML =  str;</code></pre>
        <p>Then the <code>onerror</code> attribute will be <em>automatically</em> stripped (sanitized) before <code>.innerHTML</code> gets it.</p>
        
        <p><strong><em>Hey that's pretty cool!</em></strong></p>

        <figure class="captioned-image">
    		<img src="/media/2024/monty.gif" style="width:100%;max-width:400px;" alt="one of the scenes where the castle guard is mocking arthur and his men">
    		<figcaption>It's almost like you just put defenses around all that stuff and can just peer over the wall at would be attackers and make faces at them....</figcaption>
    	</figure>

        <p>But wait... can't someone come along then and just create a more lenient policy called default?</p>
        
        <p>No! That will throw an exception!</p>

        <p>Also, you don't <em>have</em> to create a default. If you don't, and someone tries to use one of those methods to assign a string, it will throw.</p>

        <p>The only thing this enforcement cares about is that it is one of these "blessed" types. Website administrators can also provide (in the header) the name of 1 or more policies which should be created. </p>

        <p>Any attempts to define a policy not in that list will throw (it's a bit more complicated than that, see <a href="#name-your-policy">Name your Policy</a> below). Let's imagine that in the header we specified that a policy named "sanitize" is allowed to be created. </p>
        <p>Maybe you can see some of why that starts to get really interesting. In order to use any of those APIs (at all), you'd need access to a policy in order to bless the string. But because the policy which can do that blessing is a handle, it's up to you what code you give it to... </p>
        <pre><code class="language-javascript">{
  const sanitizerPolicy = 
      trustedTypes.createPolicy(
        "sanitize",
        {
          createHTML: s =&gt; { 
            return DOMPurify.sanitize(s) 
        } 
  );


    // give someOtherModule access to a sanitization policy
    someOtherModule.init(sanitizerPolicy)

    // yetAnotherModule can't even sanitize, any use of those
    // APIs will throw
    yetAnotherModule.foo()
}

// Anything out here also doesn't have 
// access to a sanitization policy
</code></pre>
        <p>What's interesting about this is that the thing doing the trusting on the client, is actually <em>on</em> the client as well - but the pattern ensures that this becomes a considerably more finite problem. It is much easier to audit whether the "trust" is warranted. That is, we can look at the above to see that there is only one policy and it only supports creating HTML. We can see that the trust there is placed in DOMPurify, and even that amount of trust is only provided to select modules.</p>
        <p>Finally, most importantly: It is a pattern that is machine enforceable. Anything that tries to use any of those APIs without a blessed string (a Trusted Type) will fail... Unless you ask it not to.</p>
    </section>
    <section class="sectioning">
        <h2 class="contextual-heading" id="dont-throw-just-help" style="font-size: 2.5rem;">Don't Throw, Just Help?</h2>
        <p>Shutting down all of those APIs after the fact is hard because all of those dangerous APIs are also really useful and therefore widely used. As I said earlier, auditing to find and understand all uses of them all is pretty difficult. Chances are pretty good that there might just be a lot more unsafe stuff floating around in your site than you expected.</p>
        <p>Instead of <code>Content-Security-Policy</code> CSP headers, you can send <code>Content-Security-Policy-Report-Only</code> and include a directive that includes <code>report-to /csp-violation-report-endpoint/</code> where <code>/csp-violation-report-endpoint/</code> is an endpoint path (on the same origin). If set, whenever violations occur, browsers should send a request to <a href="https://w3c.github.io/webappsec-csp/#report-violation">report a violation</a> to that endpoint (JSON formatted with lots of data). </p>
        <p>The general idea is that it is then pretty easy to turn this on and monitor your site to discover where you might have some problems, and begin to work through them. This should be especially good for your QA environment. Just keep in mind that the report doesn't actually prevent the potentially bad things from happening, it just lets you know they exist.</p>
    </section>
    <section class="sectioning">
        <h2 class="contextual-heading" id="shouldnt-there-just-be-a-standard-santizer-too" style="font-size: 2.5rem;">Shouldn't there just <em>be</em> a standard santizer too?</h2>
        <p><a href="https://github.com/WICG/sanitizer-api">Yes!! That is also a thing that is being worked on</a>.</p>
    </section>
    <section class="sectioning">
        <h2 class="contextual-heading" id="name-your-policy" style="font-size: 2.5rem;">Name Your Policy</h2>
        <p>I'm not going to lie, I found CSP/headers to be both a little confusing to read and to figure out their relationships. You might see a header set up to report only....</p>
        <p><code>Content-Security-Policy-Report-Only: report-uri /csp-violation-report-endpoint; default-src 'self'; require-trusted-types-for 'script'; trusted-types one two;</code></p>
        <p>Believe it or not that's a fairly simple one. Basically though, you split it up on semi-colons and each of those is a directive. The directive has a name like "report-uri" followed by whitespace and then a list of values (potentially containing only 1) which are whitespace separated. There are also keyword values which are quoted.</p>
        <p>So, the last two parts of this are about Trusted Types. The first, <code>require-trusted-types-for</code> is about what gets some kind of enforcement and really the only thing you can put there currently is the keyword <code>'script'</code>. The second, <code>trusted-types</code> is about what policies can be created.</p>
        <p>Note that I said "some kind of enforcement" because the above is "report only" which means those things will report, but not actually throw, while if we just change the name of the header from <code>Content-Security-Policy-Report-Only</code> to <code>Content-Security-Policy</code> lots of things might start throwing - which didn't greatly help my exploration. So, here's a little table that might help..</p>
        <table>
            <thead>
                <tr>
                    <th>If the directives are...</th>
                    <th>then...</th>
                </tr>
            </thead>
            <tbody>
                <tr>
                    <td><em>(missing)</em></td>
                    <td>You can create whatever policies you want (except duplicates), but they aren't enforced in any way.</td>
                </tr>
                <tr>
                    <td><code>require-trusted-types-for 'script';</code></td>
                    <td>You can create whatever policies you want (except duplicates), and they are enforced. All attempts to assign strings to those sinks will throw. This means if you create a policy named default, it will 'bless' strings through that automatically, but it also means anyone can create any policy to 'bless' strings too.</td>
                </tr>
                <tr>
                    <td><code>trusted-types</code></td>
                    <td>You cannot create any policies whatsoever. Attempts to will throw.</td>
                </tr>
                <tr>
                    <td><code>trusted-types 'none'</code></td>
                    <td>Same as with no value.</td>
                </tr>
                <tr>
                    <td><code>trusted-types a b</code></td>
                    <td>You can call <code>createPolicy</code> with names 'a' and 'b' exactly once. Attempts to call with other names (including 'default'), or repeatedly will throw.</td>
                </tr>
                <tr>
                    <td><code>trusted-types default</code></td>
                    <td>You can call <code>createPolicy</code> with names 'default' exactly once. Attempts to call with other names, or repeatedly will throw.</td>
                </tr>
                <tr>
                    <td><code>require-trusted-types-for 'script'; trusted-types a</code></td>
                    <td>You can call <code>createPolicy</code> with names 'a' exactly once. Attempts to call with other names (including default), or repeatedly will throw. All attempts to assign strings to those sinks will throw unless they are 'blessed' from a function in a policy named 'a'</td>
                </tr>
            </tbody>
        </table>
    </section>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[How We Fund the Web Ecosystem]]></title>
        <id>https://bkardell.com/blog/HowWeFund.html</id>
        <link href="https://bkardell.com/blog/HowWeFund.html">
        </link>
        <updated>2024-03-13T04:00:00.000Z</updated>
        <summary type="html"><![CDATA[On Tuesday (March 12th, 2024), Robin Berjon and Eric Meyer and I organized, led and scribed a session during W3C breakouts day about how we fund the web ecosystem‚Ä¶]]></summary>
        <content type="html"><![CDATA[
	<h1 class="contextual-heading" style="font-size: 2rem;">How We Fund the Web Ecosystem</h1>
	<p class="segue">On Tuesday (March 12th, 2024), Robin Berjon and Eric Meyer and I organized, led and scribed a session during W3C breakouts day about how we fund the web ecosystem‚Ä¶</p>


	<p>Every year the W3C has a week long giant set of in-person meetings called TPAC. A nice feature of those meetings has always been ‚ÄúBreakouts Day‚Äù which is a day where people can propose sessions about pretty much anything and we try to organize a schedule around the ones that seem interesting to enough people.</p>

	<p>This year, the W3C decided to try a second Breakouts Day that is not at the same time as TPAC, and was purely online.</p>

	<p>Over the last several years, I‚Äôve written several pieces about different aspects of the health of the web ecosystem and led a podcast series with quite a few episodes about that.  In those pieces I‚Äôve argued that while the web ecosystem has become the infrastructure for nearly everything, our models for funding and prioritization of the last 20 years have proven not only inadequate, and problematic, but ultimately fragile and cannot last.  The only questions, I‚Äôve argued, are how soon and what happens next. Are we ready for it? (hint: no).</p>


	<p>So, I talked to a few people and we proposed this as a topic. It was well attended. We began with a short presentation (we made a very detailed outline together, but credit goes to Robin for the <a href="https://bkardell.com/media/2024/How_We_Fund_The_Web.pdf" rel="noopener">great slides</a>).</p>

	<p>We organized the presentation into sort of 2 parts. First I presented explaining the problems and why we believe this requires our attention and action.  First we have to admit that we have a problem, right?  And that this is a problem that <em>we</em> should be concerned with‚Ä¶ If not us, who?  If not now, when?</p>

	<p>Then I outlined that there are many possible solutions and elements of solutions that we can discuss (or try), but all of them share some common elements:</p>

	<ol>
		<li>We need a way to take in common money, and a way to actually encourage money into the pot.</li>
		<li>We need a way to <em>efficiently</em> and <em>fairly</em> prioritize the money in the pot toward actual work.</li>
	</ol>

	<p>I highlighted that there are existing things we can already try (and are trying), and that we should really start trying more.</p>

	<p>After this, Robin presented a bigger possible vision we tried to lay out with lots of still fuzzy areas and questions - but effectively: We create an institution which is (through one of a few possibilities) able to compel participation into a system which enforces more sustainable (and fairer) characteristics which guarantee support for the infrastructure of the web.</p>

	<p>You can get a very good idea of what was actually presented from the <a href="https://github.com/w3c/breakouts-day-2024/issues/20#issuecomment-1992539848" rel="noopener">detailed outline</a> that we shared too.</p>

	<p>But all of this was only the initial short presentation which I think was only maybe 5-10 minutes.  The rest was the point of the breakout: Actual discussion.</p>

	<p>I think it was <em>very</em> positive actually.  The main thing that impressed me is that there was seemingly no push back or questioning at at all in the premise.  We agree with the fundamentals - that as I explained in <a href="https://bkardell.com/blog/Webrise.html" rel="noopener">Webrise</a>, it‚Äôs fragile from this perspective, and we need to care about it.</p>

	<p>Rick Beyers (from Google, but not speaking for Google) mentioned what they observed in Chromium contributions and that they also had concerns about diversity, both in terms of contributions to a single engine, and multiple engines.  He also mentioned that Chromium was spinning up a new collective idea (not yet announced).</p>

	<p>Just this morning, we helped launch the <a href="https://servo.org/blog/2024/03/12/sponsoring-servo/" rel="noopener">Servo collective</a>.  The timing is purely coincidental.  I‚Äôd also note that in part of my presentation I mentioned exploring ways that governments can incentivize and forgot to mention that there have been interesting developments in some open source funding happening this way recently, and to note that the White House recently made a statement that <a href="https://www.whitehouse.gov/oncd/briefing-room/2024/02/26/press-release-technical-report/" rel="noopener">Future Software Should Be Memory Safe</a>.  If anyone has a good ‚Äòin‚Äô at the White House please make the case that if you want to know a good place to invest to be sure a lot of future stuff is memory safe, it‚Äôs probably browsers - and especially the one written in Rust :). The collective would be happy to accept the White House‚Äôs check.</p>

	<p>There were also some interesting questions about whether Web Monetization could be related to this, or is just a wholly separate problem, about how the advertising model is exceptionally progressive, and where other investment comes from currently.</p>
	<p>Happily <a href="https://www.w3.org/2024/03/12-ecosystem-funding-minutes.html" rel="noopener">minutes are available</a> if you‚Äôre interested - and we‚Äôll be trying to organize some immediate discussions on where we go from here through <a href="https://github.com/darobin/wise/" rel="noopener">this repo</a> which also has <a href="https://darobin.github.io/wise/" rel="noopener">a rough outline of how one solution might work</a>.</p>
]]></content>
    </entry>
</feed>