<html lang="en" resource-type="blogpost"><head>  
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <meta name="view-transition" content="same-origin"> 

    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:site" content="@briankardell">
    <meta name="twitter:creator" content="@briankardell">
    <meta name="twitter:title" content="Listen up: Web Speech APIs Part III">
    <meta name="twitter:description" content="This is part of a series about making the browser speak and listen to speech. In my last post You Don't Say: Web Speech APIs Part II, I talked about how I'm personally papering ove">
    <meta name="twitter:image" content="../media/mic-permission-granted.png">
    <!-- meta name="monetization" content="$ilp.uphold.com/kKU4GXiRwhnf " -->
    
    <link rel="alternate" type="application/rss+xml" href="https://bkardell.com/blog/feed.rss" title="bkardell.com/blog rss feed">
    <title>Listen up: Web Speech APIs Part III</title> 
    <style>.captioned-image {
    background-color: #eaeaea;
    display: block;
    overflow: hidden;
    padding: 1rem;
    text-align: center;
    font-style: italic;
}

.captioned-image.p-attached {
    width: 40%;
    display: inline-block;
    margin: 0 1rem 2rem 1rem;
}

section > .captioned-image.p-attached {
    margin-top: 1.5rem; /* correct for heading size*/
}

 pre { overflow-x: auto }

.captioned-image.p-attached.p-attached-left {
    float: left;
}

.captioned-image.p-attached.p-attached-right {
    float: right;
}

.captioned-image.p-attached + * + * {
    clear: both;
    margin-top: 2rem;
}


.captioned-image img, .captioned-image video {
    display: block;
    max-width: 100%;
    margin: 0 auto 1em auto;
}
.source {
    font-style: italic;
}
body {
    display: grid;
    grid-template-columns: 25rem auto;
    font: 1.1rem "Helvetica Neue", Helvetica, Arial, sans-serif;
    font-weight: 400;
    line-height: 1.625;
    margin: 0;
}
h1 { margin: 0.5rem; }
code-format {
    border-left: 0.5rem solid rgba(123,115,209,0.35);
    display: block;
    padding: 0.5rem;
    margin-bottom: 1rem;
}

contextual-heading {
    display: block;
    margin-top: 2rem;
}

h1, [aria-level="1"] {
    color: #43686b;
    font-size: 1.45rem;
}

h2, [aria-level="2"] {
    color: #856363;
    font-size: 1.35rem;
}

h3, [aria-level="3"] {
    color: #856363;
    font-size: 1.25rem;
}

h4, [aria-level="4"] {
    color: #856363;
    font-size: 1.2rem;
}

h5, h6, [aria-level="5"], [aria-level="6"] {
    color: #667496;
    font-size: 1.2rem;
    font-weight: bolder;
}

.posted-on {
    font-style: italic;
    font-size: 0.8rem; 
    text-align: right;
    margin-bottom: 1rem;
}

ul, li {
    margin: 0.5rem;
    text-align: left;
}

.authorinfo {
    height: 100%;
    padding-top: 1rem;
    padding-right: 0;
    background-color: #fbf5e9; 
    display: block;
    background-image: linear-gradient(to right, #dde0e8 , #ffffff);
}

.tagline {
    font-style: italic;
    text-align: center;
}

[tag-esc] {
    color: maroon;
    font-family: Courier, "Lucida Console", monospace;
}

[tag-esc]::before {
    content: '<';
}

[tag-esc]::after {
    content: '>';
}

main {
    min-width: 50%;
    width: 80%;
    padding: 1rem;
}
header .title {
    background-color: rgba(123,115,209,0.35);
    padding: 0.3rem;
    padding-left: 0.25rem;
    font-weight: bolder;
    font-size: 1rem;
    border-left: 1rem solid #999298;
}

header .profile {
    width: 50%;
    margin: 1rem 25%;
}

header .title + nav {
    font-size: 0.9rem;
}

header .blurb {
    font-size: 0.9rem;
    text-align: center;
}
header .name {
    text-align: center;
    font-size: xx-large;
}
.segue {
    font-style: italic;
}
.sr-only {
  position: absolute;
  width: 1px;
  height: 1px;
  padding: 0;
  margin: -1px;
  overflow: hidden;
  clip: rect(0,0,0,0);
  border: 0;
}

#aboutMeToggle {
    display: none;
}

spicy-sections:not([affordance]) > h2 {
  clip: rect(0 0 0 0);
  clip-path: inset(50%);
  height: 1px;
  overflow: hidden;
  position: absolute;
  white-space: nowrap;
  width: 1px;
}

main article { max-width: 100em; margin: auto; }
/* this needs rethinking, it wants a selector like 'not flow content' */
article>*:not(contextual-heading,a), section>*:not(contextual-heading,a) {
    margin-left: 0.45rem;
}

blockquote {
  font-family: serif;
  background: #f9f9f9;
  border-left: 10px solid #ccc;
  margin: 1.5em 10px;
  padding: 0.5em 10px;
}
blockquote:before {
  color: #ccc;
  content: open-quote;
  font-size: 2em;
  line-height: 0.1em;
  margin-right: 0.25em;
  vertical-align: -0.4em;
}

blockquote:after {
  color: #ccc;
  content: close-quote;
  font-size: 2em;
  line-height: 0.1em;
  margin-left: 0.25em;
  vertical-align: -0.4em;
}
 

@media (max-width: 800px){
    body {
        grid-template-columns: 1fr;
    }
    .authorinfo {
        height: auto;
        border-bottom: 1px solid #afafff;
        padding-top:  0;
    } 

    main { width: 95%; margin: 0 auto;}

    .captioned-image.p-attached {
        width: 100%;
        margin: 1rem 0;
    }

    .captioned-image.p-attached.p-attached-left,
    .captioned-image.p-attached.p-attached-right {
        float: none;
    }

    #aboutMeToggle {
        display: block;
        background-color: #675e5e;
        color: white;
        padding: 0.25rem;
        padding-left: 0.5rem;
        border-left: 1rem solid black;
    }

    header li { display: inline; margin-left: -0.5em; }
    header .blurb li::after { content: '; '; }
    header  nav li {
        display: inline-block;
        margin-left: 0.35rem;
        margin-right: 0.35rem;
    }
    header .title {
        width: 100%;
    }
    main li .source { display: block; }

} 

spicy-sections {
    --const-mq-affordances:
      [screen and (min-width: 600px) ] collapse |
      [screen and (min-width: 801px) ] tab-bar
    ;
    display: block;
}

spicy-sections.authorinfo {
    --const-mq-affordances:
      [screen and (max-width: 801px) ] collapse
    ;
}


spicy-sections.single {
    --const-mq-affordances:
      [screen ] collapse 
;
}

[role="tab"] {
    margin-right:  1.5rem;
}

</style>
    <style> 
      .captioned-image { font-size: 0.9rem; }
      .thanksTo { font-style: italic; font-size: 0.8rem; }
    </style>
    <script>
      var activateOptional = function (media) {
        var source = media.getAttribute('data-src'),
            temp,
            container = media.parentElement;

          if (media.nextSibling && media.nextSibling.matches) {
            if (media.nextSibling.matches('.clickToSee')) {
              media.parentElement.removeChild(media.nextSibling);
            }
          }
 
          if (media.tagName === 'VIDEO') {
            temp = document.createElement('video')
            temp.setAttribute('autoplay','')
            temp.setAttribute('controls','')
            temp.setAttribute('loop','')
            temp.innerHTML = '<source src="' + source + '.webm" type="video/webm">'
                    + '<source src="' + source + '.mp4" type="video/mp4">';
            media.parentElement.replaceChild(temp, media);
            setTimeout(function () {
              temp.play()
            }, 0);
          } else {
            media.src = media.getAttribute('data-src');
          }

          container.classList.add('active');
      }
    </script>
  </head>
  <body>
    <spicy-sections class="authorinfo">
<h2 id="aboutMeToggle" defaults-on-match="">Author Information</h2>
  
<header>
    <div class="name">
        Brian Kardell
    </div>
    <img class="profile" src="/profile.jpg" alt="">
    <div class="tagline"><a href="/">Betterifying the Web</a></div>
    <div class="blurb">
        <ul>
            <li>Developer Advocate at Igalia</li>
            <li>Original Co-author/Co-signer of The Extensible Web Manifesto</li>
            <li>Co-Founder/Chair, W3C Extensible Web CG</li>
            <li>Member, W3C (OpenJS Foundation)</li>
            <li>Co-author of HitchJS</li>
            <li>Blogger</li>
            <li>Art, Science &amp; History Lover</li>
            <li>Standards Geek</li>
        </ul>
    </div>
    <div class="title">Follow Me On...</div>
    <nav>
        <ul>
            <li><a rel="me" href="https://briankardell.wordpress.com">Wordpress</a></li>
            <li><a rel="me" href="https://medium.com/@briankardell">Medium</a></li>
            <li><a rel="me" href="https://twitter.com/briankardell">Twitter</a></li>
            <li><a rel="me" href="https://github.com/bkardell/">Github</a></li>
            <li><a rel="me" href="https://toot.cafe/@bkardell">Mastodon</a></li>
            <li><a rel="me" href="https://bsky.app/profile/bkardell.com">Bluesky</a></li>
            <li><a rel="me" href="https://codepen.io/bkardell">Codepen</a></li>
            <li><a rel="me" href="https://www.linkedin.com/in/brian-kardell-08a4264">LinkedIn</a></li>
            <li><a rel="me" href="https://www.instagram.com/kardellbrian">Instagram (for
art)</a></li>
            <li><a rel="me" href="http://fineartamerica.com/profiles/brian-kardell?">Fine Art
America (art for sale)</a></li>
        </ul>
    </nav>
</header>
</spicy-sections>
<script>
  /*
    You're probably wondering "Do I need to write this?""
    "Is this part of it?"  No... If you're interested tho - 
    Custom elements have a FOUC/PE gap 
    (see https://github.com/whatwg/html/issues/6231).
    This is a slightly better experience: It 
    will be hidden _if JS is enabled_, and 
    will be shown as it is defined, 
    or after 1 sec, whichever is first.
  */
  let ss = document.createElement("style");

  ss.innerHTML = `html:not(.lldelay) :not(:defined) { visibility: hidden; }`;
  document.head.appendChild(ss);

  setTimeout(() => {
    document.documentElement.classList.add("lldelay");
  }, 1000);
</script>
    <main><div class="posted-on">Posted on 08/25/2017</div><article posted-on="08/25/2017" class="sectioning">
  <h1 class="contextual-heading">Listen up: Web Speech APIs Part III</h1>
  <p class="segue">This is part of a series about making the browser speak and listen to speech. In my last post <a href="https://bkardell.com/blog/Basic-Voice-Speaker.html">You Don't Say: Web Speech APIs Part II</a>, I talked about how I'm personally papering over what
    we "have" today with regard to making the browser "talk" and why. In this post I'll talk about the other end of that: <em>listening</em> or <em>speech-to-text</em>.</p>

  <script src="../prism.js"></script>
  <link rel="stylesheet" href="../prism.css">
  <script src="../test/speaking/basic-voice-speaker-ii.js"></script>
  <style>
    .note {
      background-color: rgba(255, 255, 0, 0.24);
      padding: 1rem;
      font-style: italic;
    }
    .note::before {
      content: 'Note';
      font-size: 0.8rem;
      background-color: black;
      color: white;
      padding: 0.25rem;
      margin-right: 0.5rem;
    }
    .output {
      margin-left: 1rem;
      font-family: "Courier New", Courier, monospace;
    }
    pre code.output {
      font-size: 0.7rem;
      border-left: 1px dotted gray;
      padding-left: 1rem;
      display: block;
    }

    .spec-quote {
      display: block;
      margin: 1rem;
    }
  </style>
  <script>
    document.body.addEventListener("click", function(evt) {
      if (evt.target.classList.contains("run")) {
        let clone = document.importNode(
          evt.target.previousElementSibling.content,
          true
        );
        document.body.appendChild(clone);
      } else if (evt.target.classList.contains("cancel")) {
        speechSynthesis.cancel();
        speechSynthesis.speak(
          new SpeechSynthesisUtterance("normalcy should be restored")
        );
      }
    });
  </script>

  <p>So far we've been talking about the unoffical Web Speech APIs in terms of speech as <em>output</em>, or text-to-speech. As I've said, this is actually supported to some degree in all modern browsers. But now we're going to talk about the other end of
    things: Speech as input or "voice recognition" or, if you prefer "speech-to-text". This is currently <em>not</em> widely supported - in fact, only Chrome has a "working" implementation popularly deployed, but it is available in FirefoxOS and available
    behind a flag while they work out some permissions issues and reportedly under development in Edge as well. It's a much harder problem in general, and there are a lot of gotchas here too. In this piece, I'll cover a lot of them.</p>


  <section class="sectioning">
    <h2 class="contextual-heading">Let's get started</h2>
    <p>Ok, so first things first: <code>webkitSpeechRecognition</code>. This is the thing that makes recognition possible. There are a number of really good articles that will tell you that you should have a line that looks something like this:
    </p>

    <pre><code class="language-javascript">
const SpeechRecognition = window.SpeechRecognition || window.mozSpeechRecognition || window.msSpeechRecognition || window.webkitSpeechRecognition;
const recognition = new SpeechRecognition();
            </code></pre>

    <p>I'm going to recommend, however, that you don't and here's why: Because we're just not far enough along to pretend we know what a compatible and standard <code>SpeechRecognition</code> will look like or that there ever will be any of those others.
      This is an approach that used to common, but that has changed and at one point we thought it was a really keen idea. Unfortunately, this interface arrived in Chrome just about the time that we began to admit to ourselves what a problem this creates.
      You'll note that nobody likes to ship vendor prefixed stuff anymore in the release channel, and here's part of the reason why: When everyone writes code like the example, it assumes that they aren't experiments or that they must be identical. Purposely,
      the original idea was that you could have a <code>webkitThingy</code> and a
      <code>msThingy</code> and a <code>mozThingy</code> and those were <em>experimental</em>. That is they might be totally different, competing experiments or simply be used to write tests and practice in order to inform what the real standard would
      be. However, in practice, the use of such patterns as the above tended to actually cause that to not be the case at all. There were 'first mover' advantages and 'market share' problems. Once we get even a couple reasonably popular uses of this API,
      the experiment now wags the standards dog because there's lots of code depending on it matching things it wasn't intended to. Both ECMA and W3C TAG have had much discussion on this problem.</p>

    <p>So, let's just be honest with ourselves and err on the side of caution and say: It's the <code>webkitSpeechRecognition</code> API at this point, and that's all we can say with absolute certainty. If we get truly interoperable implementations, how
      hard will it then be to go back and change that one line? Pretty easy, I expect.</p>

    <p>Ok so, with this in mind, we could re-write the above as:</p>

    <pre><code class="language-javascript">
const recognition = new webkitSpeechRecognition();
            </code></pre>
    <p>
      But this is just creating an interface for you, it's not <em>actually doing</em> anything yet.

      </p><section class="sectioning">
        <h3 class="contextual-heading">Events</h3>
        <p>In order to actually do anything with it, we're going to want to tell this recognizer what we actually want from it via attaching some listeners to it. There are a lot of events that we can plug into, as you will see below but in practice I haven't
          personally required many of them.</p>

        <ul>
          <li><code>audiostart</code> "Fired when the user agent has started to capture audio."</li>
          <li><code>soundstart</code> "Fired when some sound, possibly speech, has been detected."</li>
          <li><code>speechstart</code> "Fired when the speech that will be used for speech recognition has started."</li>
          <li><code>speechend</code> "Fired when the speech that will be used for speech recognition has ended."</li>
          <li><code>soundend</code> "Fired when some sound is no longer detected."</li>
          <li><code>audioend</code> "Fired when the user agent has finished capturing audio."</li>
          <li><code>result</code> "Fired when the speech recognizer returns a result." </li>
          <li><code>nomatch</code> Don't worry about this one for now, we'll come back to it.</li>
          <li><code>error</code> "Fired when a speech recognition error occurs."</li>
          <li><code>start</code> "Fired when the recognition service has begun to listen to the audio with the intention of recognizing"</li>
          <li><code>end</code> "Fired when the service has disconnected"</li>
        </ul>

        <p>A few of these are self explanatory in terms of their lifecycle: Starts have to occur before their corresponding ends. However, one could be forgiven for wondering, for example, "which happens first according to these descriptions? audio start
          or sound start?" To answer your question, let me just quote the spec:

          <span class="spec-quote">Unless specified below, the ordering of the different events is undefined. For example, some implementations may fire audioend before speechstart or speechend if the audio detector is client-side and the speech detector is server-side.</span>
        </p>

        <p class="note">If you're thinking to yourself: "Wow, that seems potentially really confusing and hard to work with," same.</p>
      </section>


      <section class="sectioning">
        <h3 class="contextual-heading">Methods</h3>
        <p>
          The recognition object also has 3 methods in charge of whether it is actively listening and feeding things to the above events:
        </p>

        <ul>
          <li><code>start</code></li>
          <li><code>stop</code></li>
          <li><code>abort</code></li>
        </ul>

        <p>
          If you're wondering what the difference between <em>stop</em> and <em>abort</em> is, it's actually pretty simple.: Stop means stop listening, but not stop processing and feeding any pending events to its listeners. Abort is a hard disconnect
          of all the things.
        </p>
      </section>

      <p>So, at it's most basic: You create a recognizer, add some listeners and call <code>.start()</code> and you should get some results until they are again disconnected (we'll come back to that in a moment)</p>

      <section class="sectioning">
        <h3 class="contextual-heading">Starting up</h3>
        <p>Before we set up an example, it's worth explaining that this feature is "different". <em>Playing</em> some media is something that has been a part of the Web for a really long time, it's not something that requires a special permission. But
          <em>listening to your microphone</em> is different, as it should be. That's something that the user has to explicitly give permission for and be made aware when it's happening. As such, when you call <code>.start()</code> Chrome will ask the
          user if it's ok for this website to use the mic. Keep in mind, they could well say "no" so you'll want to prepare for that eventuality - it will call the error handler with the <code>event.error</code> property of <code>not-allowed</code>.</p>

        <p>Even this, however, is incomplete. "Ok to access the mic" is a pretty 'simple' answer, but it's far reaching. If I want to be able to click a field and speak into it (like Google search on Android), does that mean I am also giving permission to
          listen to the conversations in the room at all other times as long as there's a tab open? That sounds terrible in most use cases, but there are use cases that are kind of almost that. This is tricky to manage, as you can imagine, so the draft
          and implementation say that the UA (browser) has to indicate to the user when it is and isn't actually listening and it has to stop when the tab is no longer active. This can take a few different forms, and we'll come back to that - but generally
          speaking, Chrome on the desktop will (currently) give a user two indicators that distinguish the difference between these two things.</p>

        <div class="captioned-image" style="background-color: inherit;">
          <img src="../media/mic-permission-granted.png" alt=""> Once the user has given permission, in the right of the address bar, it will say it is accessing the mic. That doesn't mean actively listening for speech.<p></p>
    </div>

    <div class="captioned-image" style="background-color: inherit;">
      <img src="../media/actively-listening-to-mic.png" alt=""> Once we actively start listening, in the tab itself, it will show a red "recording" dot. This dot will disappear when we stop.<p></p>
    </div>

    <p class="note">I personally have trouble believing that the average user will really understand the difference without some training which could happen the first time the mic permission is granted or something, but I've never seen. I'm also not entirely sure how
      this translates for someone who can't actually see the screen, for example. This is interesting, because that is actually the default assumption on mobile so, on Android it will play audible listening/done listening tones. I'll come back to why
      this too is currently imperfect, but let's move one.</p>
    </section>

    <section class="sectioning">
      <h3 class="contextual-heading">The most basic example</h3>
      <p>Alright, so now you know what to expect, as a user and we know basically what the API looks like, let's talk about code.</p>

      <pre><code class="language-javascript">
const recognition = new webkitSpeechRecognition(),
      basicExampleOut = document.querySelector('#basicExampleOut')

recognition.onerror = (evt) =&gt; {
    if (evt.error == 'not-allowed') {
        basicExampleOut.innerText =
            `I can't listen if you don't grant me permission :(`
    } else {
        basicExampleOut.innerText =
            `Whoops I got an ${evt.error} error`
    }
}

recognition.onresult = (evt) =&gt; {
    // What is this crazy thing?! Don't worry, we'll get to it.
    let whatIHeard = evt.results[0][0].transcript
    basicExampleOut.innerText = whatIHeard
}

recognition.start()
                </code></pre>
      <template>
                    <script>
                    (function () {
                        const recognition = new webkitSpeechRecognition(),
                              basicExampleOut = document.querySelector('#basicExampleOut')

                        recognition.onerror = (evt) => {
                            if (evt.error == 'not-allowed') {
                                basicExampleOut.innerText =
                                    `I can't listen if you don't grant me permission :(`
                            } else {
                                basicExampleOut.innerText =
                                    `Whoops I got an ${evt.error} error`
                            }
                        }

                        recognition.onresult = (evt) => {
                            // What is this crazy thing?! Don't worry, we'll get to it.
                            let whatIHeard = evt.results[0][0].transcript
                            basicExampleOut.innerText = whatIHeard
                        }

                        recognition.start()
                    }())
                    </script>
                </template>
      <button class="run">Run this and say something</button><span class="output" id="basicExampleOut">Some output will come here</span>

      <p>Note that once you got a result, it stopped listening for more results automatically. By default, this is how it works. Now let's talk about that crazy <code>evt.results[0][0].transcript</code> thing.</p>

      <section class="sectioning">
        <h4 class="contextual-heading"><code>evt.results</code></h4>
        <p><code>evt.results</code> is, as you might have guessed a collection. Unfortunately, it is not a true <code>Array</code> (very sadly since other things in the TTS portions covered in previous articles are) but another weird array-like thing called
          a <code>SpeechRecognitionResults</code>. By default, it will have exactly one item. It contains, in turn, individial <code>SpeechRecognitionResult</code> objects.</p>


        <p>So just what is a <code>SpeechRecognitionResult</code>? <em>By default, its basically also an array-like with just one item</em> called a <code>SpeechRecognitionAlternative</code>. Wait what? I know, it seems weird, but stick with me...</p>

        <p><code>SpeechRecognitionAlternative</code> is really the 'thing' that you want and <code>.transcript</code> is the text it transcribed from what it heard on the mic. This object also has property called <code>confidence</code> which is a numeric
          value between 0 and 1 representing how confident the recogntion system is that it got that right.</p>

            <pre><code class="language-javascript">
recognition.onresult = (evt) =&gt; {
        // evt.results is an array-like collection of
        // SpeechRecognitionResult objects
    let speecRecognitionResults = evt.results,

        // it's a collection of exactly one by default (see below),
        // but that is also array-like
        speechReognitionAlternatives = speechRecognitionResults[0]

        // but that also contains by default exactly one
        alternative = speechRecognitionAlternatives[0]

        // and _that_ thing has all the properties
        console.log(alternative.transcript)

}
                            </code></pre>

        <p>You are undoubtedly thinking "Wow, why all the complexity?!" To understand this, you need to note that several times above I said "by default". That's because the draft also provides for other use cases and we really need go no further than this
          next property/example to see why..</p>

        <section class="sectioning">
            <h5 class="contextual-heading">Max Alternatives</h5>

            <p>The recognizer we set up has a property called <code>maxAlternatives</code> which is a numeric value indicating how many alternatives we're willing to receive. Let's take the following example:</p>

            <pre><code class="language-javascript">
var recog = new webkitSpeechRecognition()
recog.maxAlternatives = 10
recog.onerror = (evt) =&gt; {
   debugger
}
recog.onresult = (evt) =&gt; {
   let alternatives = Array.from(evt.results[0])
   alternatives.forEach((result) =&gt; {
      console.log(
        `
        confidence: ${result.confidence}
        transcript: "${result.transcript}"
        `)
   })
}
recog.start()
            </code></pre>

            <p>If I run this in Chrome, on my desktop mac, and then say "Tutu" it will log something <em>like</em> this:</p>
            <pre><code class="output">confidence: 0.7706348896026611
transcript: "tutu"

confidence: 0.9056409001350403
transcript: "two two"

confidence: 0.9139654040336609
transcript: "to to"

confidence: 0.9311671257019043
transcript: "2 2"

confidence: 0.933784008026123
transcript: "- 2"

confidence: 0.9352703094482422
transcript: "too too"

confidence: 0.9483599662780762
transcript: "22"

confidence: 0.9183915853500366
transcript: "TuTiTu"

confidence: 0.9120156168937683
transcript: "to 2"

confidence: 0.9352703094482422
transcript: "tu tu"</code></pre>

                <p>If, however, I run the same code and say "Desmond Tutu", I get only a single result:</p>
                <pre><code class="output">confidence: 0.9614496827125549
        transcript: "Desmond Tutu"</code></pre>
                <p>So, as you can see, speech can be ambiguous and depending on the quality of the implementation of the thing transcribing speech and the amount of context you hand them, the quality of the mic and the voice/pronounciation/accent of the speaker, they may be able to, or want to give you alternatives if they can't be very sure.  And - well - if you're into that sort of thing and prepared to deal with that yourself, that's pretty cool.</p>

                <p>Ok, but what about that <code>SpeechRecognitionResults</code> thing... Why is <em>that</em> an array-like??  Why do we still grab the first one in that last example?  Hang in there...</p>
            </section>

            <section class="sectioning">
                <h5 class="contextual-heading"><code>.continuous</code></h5>
                <p>The recognizer you create also has a <code>.continuous</code> property which, by default is false.  The idea is that there are use cases (like dictation) in which once the user has indicated that they want the program to start listening, we do not actually want it to stop (or miss anything) until it's told to. That's "continuous mode".</p>

                <p>If the "continuous mode" flag is set then <code>evt.results</code> will have one more item each time and you'll want the <code>evt.results[evt.results.length-1]</code> to get 'this one'.</p>

                <p class="note">Chrome on the desktop's implementation is buggy and shows it still
                recording after page refresh despite the fact that you have no way to now tell it to stop
                or to get the results it's grabbing anymore.  Basically, you have to kill the tab to
                get it to stop as far as I can tell, which seems awful.</p>


                <p class="note">Firefox doesn't support this.  They say you can have the handling of one
                result just start listening again.  That is indeed much simpler, probably much easier on
                the memory and very nearly approximate - except on mobile where start/stop listening
                is accompanied by audible tones.</p>

            </section>
        </section>


        <section class="sectioning">
            <h4 class="contextual-heading">"Other" bits</h4>
            <p><code>SpeechRecognition</code> (the recognizer object you create) has some 'other bits' too...</p>


            <p>There's a <code>.lang</code> property.  Like speech, it defaults to the document language and can be a string representing a <a href="http://www.rfc-editor.org/rfc/bcp/bcp47.txt">BCP 47 language tag</a> (like en-US) which changes the dictionaries it's recognizing against.  So, setting it to <code>it</code>, will make it recognize Italian, but not English or Japanese.</p>

            <p class="note">As it was with utterances, setting this to something invalid, like for example,
            "Pittsburghese" will simply cause it to use the default.</p>

            <p>There's a <code>.serviceURI</code> property which is supposed to let you
            choose which recognition service to use if not the default one.
            In theory, being a <code>URI</code> it can be either a
            local service or a remote URL. </p>

            <p class="note"> In theory, it would also "work" - but it seems to be ignored
            entirely in Chrome and so I see little point in saying much more about it here.</p>

            <p>There's a <code>.grammars</code> property which is another array-like called a <code>SpeechGrammarList</code> with two methods for modifying it: <code>.addFromURI(in DOMString src,
                        optional float weight)</code> and <code>.addFromString(in DOMString string,
                        optional float weight)</code>.  The idea here is to allow you to express
                        domain specific grammars as a kind of weighted rule-set.</p>
            <p class="note">As near as I can tell, here's what the draft as to say about what grammars are supported: <code style="font-style: normal" aria-hidden="true">¯\_(ツ)_/¯</code><span class="sr-only">shrug</span>.
            You'll see some examples (for example on MDN) that show these using, for example, JSGF (Java Speech Grammar Format).  Note, that's not really a 'standard' as far as I can tell either, there's a W3C note about it. In any case, it's unspecified currently how it will work <em>without</em> a grammar or entirely how those should work and <em>in practice</em> in Chrome I was unable to find any difference at all whether you set it or not, so again, little point in saying more about it here and now beyond that.</p>

        </section>

    </section>

    <section class="sectioning">
      <h3 class="contextual-heading">Wrapping up</h3>
      <p>So, it's interesting.  It works experimentally, if you can use only the parts that work.  It isn't nearly as far along 'in practice' as the text-to-speech APIs and even the limited implementations we have have some wonky bits... In my next post, I'll talk about how I am dealing with the wonky bits of this,
      and putting together some interesting things you can do with it.
      </p>
    </section>

  </section>
  <p class="thanksTo">Special thanks to my friend, the great Chris Wilson for proofing/commenting on pieces in this series.</p>

</article></main>
 
   
  <script>
    //import { MediaAffordancesElement } from "./MediaAffordancesElement.js";
    class MediaAffordancesElement extends HTMLElement {
      constructor() {
        super();
        // todo: this should be a private field
        this.__matching = new Set()
        this.mqls = [];
        this.observers = [];

        this.supportedAffordances = new Set();
      }

      observeAffordanceChange(cb) {
        this.observers.push(cb);
      }

      notifyChange() {
        let intersection = new Set();
        for (let elem of this.__matching) {
          if (this.supportedAffordances.has(elem)) {
            intersection.add(elem);
          }
        }

        if (this.__matching.size > 0) {
          this.setAttribute("mq-matched", [...this.__matching].join(" "));
        } else {
          this.removeAttribute("mq-matched");
        }
        let arr =  [...intersection]
        let affordance = arr[arr.length - 1];
        if (affordance) {
          this.setAttribute("affordance", affordance);
        } else {
          this.removeAttribute("affordance");
        }
        this.observers.forEach(cb => {
          cb(intersection, this.__matching);
        });
      }

      static get observedAttributes() {
        return ["mq-affordances"];
      }

      connectedCallback() {
        let newValue = getComputedStyle(this).getPropertyValue(
          "--const-mq-affordances"
        );
        this.connectListeners(newValue);
      }

      connectListeners(newValue = "") {
        if (newValue.trim().length === 0) {
          return;
        }
        
        newValue.split("|").forEach(segment => {
          let mq = segment.trim().match(/\[([^\]]*)/)[1];
          let names = segment
            .replace(`[${mq}]`, "")
            .trim()
            .split(" ");
          let mql = window.matchMedia(mq);
          let mqh = evt => {
            names.forEach(name => {
              this.__matching[mql.matches ? "add" : "delete"](name);
            });

            this.notifyChange();
          };
          mqh();
          mql.addEventListener("change", mqh);
          this.mqls.push(mql);
        }, this);
      }

      attributeChangedCallback(name, oldValue, newValue) {
        this.connectListeners(newValue);
      }
    }

    //-----------------------------------------------------

    (function() {
      let lastUId = 0;
      let nextUId = () => {
        return `cp${++lastUId}`;
      };

      let getLabels = regionset => {
        return [...regionset.children].filter(el => /^H\d$/.test(el.tagName));
      };

      let getContentEls = regionset => {
        return [...regionset.children].filter(el => !/^H\d$/.test(el.tagName));
      };

      let ensureId = el => {
        el.id = el.id || nextUId();
        return el.id;
      };

      let getDisclosureButton = label => {
        return label.shadowRoot.querySelector("button");
      };

     
      let style = document.createElement('style')
      style.innerHTML = `
          
        :where(spicy-sections > [affordance*="collapse"])::before { 
          content: ' ';
          display: inline-block;
          width: 0.5em;
          height: 0.75em;
          margin: 0 0.4em 0 0;
          transform: rotate(90deg);
          background-image: url("data:image/svg+xml;charset=UTF-8,%3csvg xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink' x='0px' y='0px' width='10px' height='10px' viewBox='0 0 270 240' enable-background='new 0 0 270 240' xml:space='preserve'%3e%3cpolygon fill='black' points='5,235 135,10 265,235 '/%3e%3c/svg%3e ");
          background-size: 100% 100%;
        } 

        :where(spicy-sections > [affordance*="collapse"][aria-expanded="true"])::before, 
        :where(spicy-sections > [affordance*="collapse"][aria-expanded="true"])::after {
          transform: rotate(180deg);
        }
      `
      document.head.prepend(style)
      
      const template = `
            <style>
              :root {
                font-size: 1rem;
              }

              :host([hidden]),
              ::slotted([hidden]) {
                display: none;
              }
              
              ::slotted(h1),
              ::slotted(h2),
              ::slotted(h3),
              ::slotted(h4),
              ::slotted(h5),
              ::slotted(h6) {
                 margin-right: 1rem;
              }
              
              tab-bar ::slotted([tabindex="0"]) {
                border-bottom: 1px solid blue;
              }
              
              tab-list { 
                display: flex; 
                overflow: hidden;
                white-space: nowrap;
              }
            </style>
            <tab-bar part="tab-bar">
              <!-- The region/tablist should have a  label -->
              <tab-list part="tab-list" role="tablist"
              ><slot name="tabListSlot"></slot></tab-list>
            </tab-bar>
            <content part="content-panels">
              <slot default></slot>
            </content>
        `;

      class RegionSet extends MediaAffordancesElement {
        __defaults;
        __tabListEl;

        // tabs and exclusive collapses should have the same affordance object?
        __affordanceConf = {
          collapse: {
            // can take a condition to force, check-like
            toggle: (label, condition) => {
              let state =
                typeof condition === "boolean"
                  ? condition
                  : !label.affordanceState.expanded;
              let contentEl = label.nextElementSibling;
              label.affordanceState.expanded = state;
              label.affordanceState.nonExclusiveExpanded = state;
              label.setAttribute("aria-expanded", state);
              if (state) {
                label.setAttribute("expanded", "");
                contentEl.style.display = "block";
              } else {
                label.removeAttribute("expanded");
                contentEl.style.display = "none";
              }
            }
          },
          "exclusive-collapse": {
            // ignores condition, radio-like
            toggle: label => {
              let labels = getLabels(label.parentElement);
              let siblings = labels.filter(c => c !== label);
              let index = labels.findIndex(c => c === label);

              siblings.forEach((sibLabel, i) => {
                let relatedContent = sibLabel.nextElementSibling;
                sibLabel.tabIndex = -1;
                relatedContent.style.display = "none";
                label.setAttribute("aria-expanded", "false");
                sibLabel.affordanceState.exclusiveExpanded = false;
              });
              label.tabIndex = 0;
              //nope - todo, fix/remove this?
              label.parentElement.affordanceState.exclusiveSelection.index = index;
              label.nextElementSibling.style.display = "block";
              label.setAttribute("aria-expanded", "true");
              label.affordanceState.exclusiveExpanded = true;
              label.focus();
            }
          },
          "tab-bar": {
            // ignores condition, radio-like
            toggle: label => {
              let labels = getLabels(label.parentElement);
              let siblings = labels.filter(c => c !== label);
              let index = labels.findIndex(c => c === label);

              siblings.forEach((sibLabel, i) => {
                let relatedContent = sibLabel.nextElementSibling;
                sibLabel.tabIndex = -1;
                relatedContent.style.display = "none";
                sibLabel.setAttribute("aria-expanded", "false");
                sibLabel.affordanceState.exclusiveExpanded = false;
              });
              label.tabIndex = 0;
              label.parentElement.affordanceState.exclusiveSelection.index = index;
              label.nextElementSibling.style.display = "block";
              label.setAttribute("aria-expanded", "true");
              label.affordanceState.exclusiveExpanded = true;
              label.focus();
            }
          }
        };
        __setSize = (labelEls, contentEls) => {
          this.__size = Math.min(labelEls.length, contentEls.length);

          if (labelEls.length !== this.__size) {
            console.warn("mismatch in tab-set label/content pairs...");
          }

          labelEls.forEach((labelEl, i) => {
            let contentEl = contentEls[i];
            if (!labelEl.initialized) {
              labelEl.initialized = true; // todo: this used to be shadow, do i need it?
              let defs = this.__defaults.defaultActive;

              // this assumes it is about collapses
              labelEl.affordanceState = {
                expanded: defs.includes(labelEl),
                active: false,
                // activate in the current mode
                activate: () => {
                  if (this.affordanceState.current) {
                    this.__affordanceConf[this.affordanceState.current].toggle(
                      labelEl
                    );
                  }
                }
              };

              let defaultExclusive =
                defs.length === 0 ? labelEls[0] : defs[defs.length - 1];

              this.affordanceState.exclusiveSelection.index = labelEls.indexOf(
                defaultExclusive
              );
            }
            labelEl.setMode = mode => {
              if (mode === "non-exclusive") {
                let isExpanded = labelEl.affordanceState.expanded;
                labelEl.setAttribute("affordance", "collapse");
                labelEl.setAttribute("tabindex", "0");
                labelEl.setAttribute("aria-controls", contentEl.id);
                labelEl.setAttribute("role", "button");
                labelEl.setAttribute("aria-expanded", isExpanded);
                labelEl.nextElementSibling.style.display = isExpanded
                  ? "block"
                  : "none";
              } else if (mode === "exclusive") {
                let isExpanded =
                  labelEls.indexOf(labelEl) ===
                  this.affordanceState.exclusiveSelection.index;
                labelEl.setAttribute("affordance", "collapse");
                labelEl.setAttribute("tabindex", isExpanded ? 0 : -1);
                labelEl.setAttribute("role", "button");
                labelEl.setAttribute("aria-expanded", isExpanded);
                labelEl.setAttribute("aria-controls", contentEl.id);
                labelEl.nextElementSibling.style.display = isExpanded
                  ? "block"
                  : "none";
              } else {
                labelEl.removeAttribute("tabIndex");
                labelEl.removeAttribute("affordance");
                labelEl.removeAttribute("aria-expanded");
                labelEl.removeAttribute("role");
              }
            };
          });
        };

        __projectTabBar = () => {
          this.__removeProjections();
          getLabels(this).forEach((tabSource, i) => {
            let selected = false,
              tabIndex = -1,
              display = "none";

            tabSource.setMode();
            tabSource.slot = "tabListSlot";
            tabSource.setAttribute("role", "tab");
            let tabId = ensureId(tabSource);
            let contentSource = tabSource.nextElementSibling;
            contentSource.tabIndex = 0;
            tabSource.setAttribute("aria-controls", ensureId(contentSource));
            contentSource.setAttribute("role", "tabpanel");
            contentSource.setAttribute("aria-labelledby", tabSource.id);
            if (i === this.affordanceState.exclusiveSelection.index) {
              tabIndex = 0;
              selected = true;
              display = "block";
            }
            tabSource.setAttribute("aria-selected", selected);
            tabSource.tabIndex = tabIndex;
            contentSource.style.display = display;

            // TODO: aria-orientation :(
          });
        };

        __projectCollapses = exclusive => {
          // TODO - remove projections and... ??
          this.__removeProjections();
          getLabels(this).forEach(label => {
            label.setMode(exclusive ? "exclusive" : "non-exclusive");
          });
        };

        __removeProjections = () => {
          [...this.children].forEach(child => {
            child.removeAttribute("slot");
            child.removeAttribute("affordance")
            child.removeAttribute("role");
            child.removeAttribute("aria-selected");
            child.removeAttribute("aria-controls");
            child.removeAttribute("tabindex");
            child.removeAttribute("aria-expanded")
            child.style.display = "block";
          });
        };

        // matching pairs
        __size = 0;

        __configure = () => {
          ///hmmm

          this.__setSize(getLabels(this), getContentEls(this));

          if (this.affordanceState.current === "tab-bar") {
            this.affordanceState.currentMode = "exclusive";
            this.__projectTabBar();
          } else if (this.affordanceState.current === "collapse") {
            this.affordanceState.currentMode = "non-exclusive";
            this.__projectCollapses();
          } else if (this.affordanceState.current === "exclusive-collapse") {
            this.affordanceState.currentMode = "exclusive";
            this.__projectCollapses(true);
          } else {
            this.affordanceState.currentMode = undefined;
            this.__removeProjections();
          }

          let specifiedIndex = this.activeTabIndex || 0;
          // TODO: hmm, these are DOM changes, we could cache them
          let labelEls = getLabels(this);
          let contentEls = getContentEls(this);

          for (let i = 0; i < this.__size; i++) {
            let label = labelEls[i];
            // probably add one handler that decides
            if (!label._inited) {
              label.addEventListener("click", evt => {
                evt.target.affordanceState.activate();
              });
              label._inited = true;
            }
          }
        };
        
        __childListObserver = new MutationObserver(mutationList => {
          // we have to wire up new elements
          let labelEls = getLabels(this);
          let contentEls = getContentEls(this);

          // what if there is a mismatch?
          this.__setSize(labelEls, contentEls);
          this.__configure();
        });

        __tabset;

        affordanceState = {
          exclusiveSelection: { index: undefined },
          current: undefined,
          currentMode: undefined,
          getLabels: () => {
            return getLabels(this);
          }
        };

        /*
          Wires up suppored affordances...
        */
        constructor() {
          super();
          this.supportedAffordances.add("tab-bar");
          this.supportedAffordances.add("collapse");
          this.supportedAffordances.add("exclusive-collapse");

          this.observeAffordanceChange((matching, all) => {
            if (!this.__defaults) {
              this.__defaults = {
                onMatch: this.hasAttribute("defaults-on-match"),
                defaultActive: getLabels(this).filter(l =>
                  l.hasAttribute("default-activate")
                )
              };
            }
            this.affordanceState.current = this.getAttribute("affordance");
            this.__configure();
          });

          this.attachShadow({ mode: "open" });
          this.shadowRoot.innerHTML = template;
     
          this.__tabListEl = this.shadowRoot.querySelector("tab-list");
          this.addEventListener(
            "keydown",
            evt => {
              let labels = getLabels(this);
              let size = labels.length;
              let cur = this.affordanceState.exclusiveSelection.index;
              let prev = cur === 0 ? size - 1 : cur - 1;
              let next = cur === size - 1 ? 0 : cur + 1;

              if (
                this.affordanceState.current === "tab-bar" ||
                this.affordanceState.current === "exclusive-collapse"
              ) { 
                if (evt.keyCode == 37 || evt.keyCode == 38) {
                  labels[prev].affordanceState.activate();
                } else if (evt.keyCode == 39 || evt.keyCode == 40) {
                  labels[next].affordanceState.activate();
                }
              } else if (evt.keyCode == 32 && this.affordanceState.current === 'collapse') {
                evt.preventDefault()
              }
            },
            false
          );
          this.addEventListener(
            "keyup", 
            evt => {
              if (evt.keyCode == 32 && this.affordanceState.current === 'collapse') {
                evt.target.closest('[affordance]').affordanceState.activate()
                evt.preventDefault()
              }
            })
        }

        connectedCallback() {
          super.connectedCallback();

          //TODO: check whether there is a hash/handle selection
          
          // If you append a fragment with a pair, it should work
          this.__childListObserver.observe(this, { childList: true });
        }
      }
      customElements.define("spicy-sections", RegionSet);
    })();
    </script>
  <script>
    Array.prototype.slice.call(document.querySelectorAll('.optional [data-src]')).forEach(function (optional) {
      var prefs = window.localStorage.downloadsPrefs,
          clickToSee;
      if (prefs === 'true') {
        activateOptional(optional);
      } else {
        clickToSee = document.createElement('div');
        clickToSee.classList.add('clickToSee')
        clickToSee.innerHTML = '<button>Click to see media</button>';
        clickToSee.style.textAlign = 'center';
        clickToSee.style.border = 'none';
        optional.parentElement.insertBefore(clickToSee, optional.nextSibling);
        clickToSee.firstElementChild.addEventListener('click', function () {
          activateOptional(optional);
        })
      }

    })
  </script>

</body></html>